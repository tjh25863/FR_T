"""
èŠ±å‰è¯†åˆ«AIæŒ‘æˆ˜èµ› - é¢„æµ‹è„šæœ¬ (ä¼˜åŒ–ç‰ˆ)
AI Competition Coach - Flower Recognition Challenge Prediction v1.1.0

ä¼˜åŒ–å†…å®¹:
1. ğŸŒ¡ï¸ æ”¯æŒæ¸©åº¦ç¼©æ”¾çš„æ¨ç†
2. ğŸ¯ TTA (Test Time Augmentation) é›†æˆ
3. ğŸ“Š ç½®ä¿¡åº¦æ ¡å‡†å’Œç»Ÿè®¡
4. ğŸ”„ æ‰¹é‡é¢„æµ‹ä¼˜åŒ–
5. ğŸ“‹ å¢å¼ºçš„æäº¤æ–‡ä»¶ç”Ÿæˆ
6. ğŸ›¡ï¸ é”™è¯¯å¤„ç†å’Œæ¢å¤æœºåˆ¶

ä½¿ç”¨æ–¹æ³•:
python predict.py --config config.json --model_path models/best_model.pth --test_dir data/test_images --output results/submission.csv --use_tta
"""

import os
import argparse
import time
from pathlib import Path
from typing import Dict, List, Tuple, Optional

import torch
import torch.nn as nn
import torch.nn.functional as F
from torch.utils.data import DataLoader
import numpy as np
import pandas as pd
from tqdm import tqdm
from PIL import Image
import warnings
warnings.filterwarnings('ignore')

# å¯¼å…¥è‡ªå®šä¹‰æ¨¡å—
from model import FlowerViTModel, ModelFactory, ModelUtils
from utils import (
    Logger, ConfigLoader, set_seed_strict, FlowerDataset,
    get_test_transforms, get_tta_transforms, create_submission_file,
    format_time, load_class_mappings
)


class OptimizedPredictor:
    """ä¼˜åŒ–çš„é¢„æµ‹å™¨ç±»"""

    def __init__(self, config: Dict, model_path: str):
        """
        åˆå§‹åŒ–é¢„æµ‹å™¨

        Args:
            config: é…ç½®å­—å…¸
            model_path: æ¨¡å‹æƒé‡è·¯å¾„
        """
        self.config = config
        self.model_path = model_path
        self.logger = Logger(config['paths']['logs_dir'])
        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')

        # è®¾ç½®éšæœºç§å­
        if config.get('reproducibility', {}).get('deterministic', True):
            set_seed_strict(config['reproducibility']['seed'])

        self.logger.info("ğŸš€ ä¼˜åŒ–é¢„æµ‹å™¨åˆå§‹åŒ–å®Œæˆ")
        self.logger.info(f"ğŸ”§ ä½¿ç”¨è®¾å¤‡: {self.device}")

        # åŠ è½½æ¨¡å‹
        self.model = self._load_model()

        # åŠ è½½ç±»åˆ«æ˜ å°„
        self.class_to_idx, self.idx_to_class = load_class_mappings(
            config['data']['class_mapping'])

    def _load_model(self) -> nn.Module:
        """åŠ è½½è®­ç»ƒå¥½çš„æ¨¡å‹"""
        self.logger.info(f"ğŸ“¥ åŠ è½½æ¨¡å‹: {self.model_path}")

        # åˆ›å»ºæ¨¡å‹
        model = ModelFactory.create_vit_model(self.config)
        model = model.to(self.device)

        # åŠ è½½æƒé‡
        try:
            load_info = ModelUtils.load_model_weights(model, self.model_path, strict=False)

            if 'error' not in load_info:
                self.logger.info("âœ… æ¨¡å‹æƒé‡åŠ è½½æˆåŠŸ")

                # è®°å½•æ¨¡å‹ä¿¡æ¯
                if 'checkpoint_info' in load_info:
                    info = load_info['checkpoint_info']
                    if 'metrics' in info:
                        metrics = info['metrics']
                        self.logger.info(f"ğŸ“Š æ¨¡å‹æ€§èƒ½:")
                        self.logger.info(f"   éªŒè¯å‡†ç¡®ç‡: {metrics.get('accuracy', 0):.4f}")
                        self.logger.info(f"   Top-5å‡†ç¡®ç‡: {metrics.get('top5_accuracy', 0):.4f}")
                        self.logger.info(f"   ç«èµ›å¾—åˆ†: {metrics.get('competition_score', 0):.4f}")
            else:
                self.logger.error(f"âŒ æ¨¡å‹åŠ è½½å¤±è´¥: {load_info['error']}")
                raise Exception(load_info['error'])

        except Exception as e:
            self.logger.error(f"âŒ æ¨¡å‹æƒé‡åŠ è½½å¤±è´¥: {e}")
            raise e

        model.eval()
        return model

    def _prepare_test_dataloader(self, test_dir: str, use_tta: bool = False) -> DataLoader:
        """å‡†å¤‡æµ‹è¯•æ•°æ®åŠ è½½å™¨"""
        self.logger.info(f"ğŸ“‚ å‡†å¤‡æµ‹è¯•æ•°æ®: {test_dir}")

        # æ”¶é›†æµ‹è¯•å›¾åƒ
        test_dir = Path(test_dir)
        image_paths = []

        if test_dir.is_dir():
            # æ”¯æŒå¤šç§å›¾åƒæ ¼å¼
            valid_extensions = {'.jpg', '.jpeg', '.png', '.bmp', '.tiff'}
            for ext in valid_extensions:
                image_paths.extend(test_dir.glob(f'*{ext}'))
                image_paths.extend(test_dir.glob(f'*{ext.upper()}'))
        else:
            raise ValueError(f"æµ‹è¯•ç›®å½•ä¸å­˜åœ¨: {test_dir}")

        image_paths = [str(p) for p in sorted(image_paths)]
        self.logger.info(f"ğŸ“Š æ‰¾åˆ°æµ‹è¯•å›¾åƒ: {len(image_paths)} å¼ ")

        if len(image_paths) == 0:
            raise ValueError("æµ‹è¯•ç›®å½•ä¸­æ²¡æœ‰æ‰¾åˆ°æœ‰æ•ˆå›¾åƒ")

        # é€‰æ‹©å˜æ¢
        if use_tta:
            # TTAæ¨¡å¼ï¼šåˆ›å»ºå¤šä¸ªå˜æ¢
            transforms_list = get_tta_transforms(
                self.config, 
                self.config['inference'].get('tta_steps', 5)
            )
            self.logger.info(f"ğŸ¯ TTAæ¨¡å¼: {len(transforms_list)} ç§å˜æ¢")
        else:
            # æ ‡å‡†æ¨¡å¼
            transforms_list = [get_test_transforms(self.config)]
            self.logger.info("ğŸ¯ æ ‡å‡†æ¨ç†æ¨¡å¼")

        # åˆ›å»ºæ•°æ®é›†å’ŒåŠ è½½å™¨
        datasets = []
        for transform in transforms_list:
            dataset = FlowerDataset(
                image_paths=image_paths,
                labels=None,  # æµ‹è¯•æ¨¡å¼ä¸éœ€è¦æ ‡ç­¾
                transform=transform
            )
            datasets.append(dataset)

        return datasets, image_paths

    def _predict_single_batch(self, images: torch.Tensor, 
                            temperature: float = 1.0) -> Tuple[torch.Tensor, torch.Tensor]:
        """
        é¢„æµ‹å•ä¸ªæ‰¹æ¬¡

        Args:
            images: è¾“å…¥å›¾åƒæ‰¹æ¬¡
            temperature: æ¸©åº¦ç¼©æ”¾å‚æ•°

        Returns:
            predictions, confidences
        """
        with torch.no_grad():
            # å‰å‘ä¼ æ’­
            logits = self.model(images.to(self.device))

            # åº”ç”¨æ¸©åº¦ç¼©æ”¾
            if temperature != 1.0:
                logits = logits / temperature

            # è®¡ç®—æ¦‚ç‡å’Œé¢„æµ‹
            probs = F.softmax(logits, dim=1)
            confidences, predictions = torch.max(probs, dim=1)

        return predictions.cpu(), confidences.cpu()

    def _predict_with_tta(self, datasets: List[FlowerDataset], 
                         image_paths: List[str], batch_size: int = 64) -> List[Tuple[str, int, float]]:
        """
        ä½¿ç”¨TTAè¿›è¡Œé¢„æµ‹

        Args:
            datasets: æ•°æ®é›†åˆ—è¡¨ï¼ˆä¸åŒå˜æ¢ï¼‰
            image_paths: å›¾åƒè·¯å¾„åˆ—è¡¨
            batch_size: æ‰¹æ¬¡å¤§å°

        Returns:
            é¢„æµ‹ç»“æœåˆ—è¡¨
        """
        self.logger.info("ğŸ¯ å¼€å§‹TTAé¢„æµ‹...")

        num_images = len(image_paths)
        num_augmentations = len(datasets)

        # å­˜å‚¨æ‰€æœ‰å˜æ¢çš„é¢„æµ‹ç»“æœ
        all_probs = np.zeros((num_images, num_augmentations, self.config['model']['num_classes']))

        # å¯¹æ¯ç§å˜æ¢è¿›è¡Œé¢„æµ‹
        for aug_idx, dataset in enumerate(datasets):
            self.logger.info(f"ğŸ”„ TTAå˜æ¢ {aug_idx+1}/{num_augmentations}")

            dataloader = DataLoader(
                dataset,
                batch_size=batch_size,
                shuffle=False,
                num_workers=min(4, os.cpu_count()),
                pin_memory=True
            )

            batch_start_idx = 0
            for images, _ in tqdm(dataloader, desc=f'TTA {aug_idx+1}', leave=False):
                batch_size_actual = images.size(0)

                # é¢„æµ‹
                with torch.no_grad():
                    logits = self.model(images.to(self.device))
                    probs = F.softmax(logits, dim=1).cpu().numpy()

                # å­˜å‚¨æ¦‚ç‡
                end_idx = batch_start_idx + batch_size_actual
                all_probs[batch_start_idx:end_idx, aug_idx] = probs
                batch_start_idx = end_idx

        # é›†æˆé¢„æµ‹ç»“æœï¼ˆå¹³å‡æ¦‚ç‡ï¼‰
        self.logger.info("ğŸ”€ é›†æˆTTAé¢„æµ‹ç»“æœ...")
        ensemble_probs = np.mean(all_probs, axis=1)
        predictions = np.argmax(ensemble_probs, axis=1)
        confidences = np.max(ensemble_probs, axis=1)

        # ç”Ÿæˆç»“æœ
        results = []
        for i, image_path in enumerate(image_paths):
            image_id = Path(image_path).stem
            pred_class = int(predictions[i])
            confidence = float(confidences[i])
            results.append((image_id, pred_class, confidence))

        return results

    def _predict_standard(self, datasets: List[FlowerDataset], 
                         image_paths: List[str], batch_size: int = 64) -> List[Tuple[str, int, float]]:
        """
        æ ‡å‡†é¢„æµ‹æ¨¡å¼

        Args:
            datasets: æ•°æ®é›†åˆ—è¡¨ï¼ˆå•ä¸ªå˜æ¢ï¼‰
            image_paths: å›¾åƒè·¯å¾„åˆ—è¡¨
            batch_size: æ‰¹æ¬¡å¤§å°

        Returns:
            é¢„æµ‹ç»“æœåˆ—è¡¨
        """
        self.logger.info("ğŸ¯ å¼€å§‹æ ‡å‡†é¢„æµ‹...")

        dataset = datasets[0]  # åªä½¿ç”¨ç¬¬ä¸€ä¸ªå˜æ¢
        dataloader = DataLoader(
            dataset,
            batch_size=batch_size,
            shuffle=False,
            num_workers=min(4, os.cpu_count()),
            pin_memory=True
        )

        results = []
        temperature = self.config['model'].get('temperature', 1.0)

        batch_start_idx = 0
        for images, image_ids in tqdm(dataloader, desc='é¢„æµ‹ä¸­'):
            # é¢„æµ‹
            predictions, confidences = self._predict_single_batch(images, temperature)

            # å¤„ç†ç»“æœ
            for i in range(len(image_ids)):
                image_id = image_ids[i]
                pred_class = int(predictions[i])
                confidence = float(confidences[i])
                results.append((image_id, pred_class, confidence))

        return results

    def predict(self, test_dir: str, output_path: str, 
               use_tta: bool = False, batch_size: Optional[int] = None) -> pd.DataFrame:
        """
        ä¸»é¢„æµ‹å‡½æ•°

        Args:
            test_dir: æµ‹è¯•å›¾åƒç›®å½•
            output_path: è¾“å‡ºæ–‡ä»¶è·¯å¾„
            use_tta: æ˜¯å¦ä½¿ç”¨TTA
            batch_size: æ‰¹æ¬¡å¤§å°

        Returns:
            é¢„æµ‹ç»“æœDataFrame
        """
        start_time = time.time()

        # ä½¿ç”¨é…ç½®ä¸­çš„æ‰¹æ¬¡å¤§å°
        if batch_size is None:
            batch_size = self.config['inference']['batch_size']

        self.logger.info(f"ğŸš€ å¼€å§‹é¢„æµ‹ä»»åŠ¡")
        self.logger.info(f"ğŸ“‚ æµ‹è¯•ç›®å½•: {test_dir}")
        self.logger.info(f"ğŸ“„ è¾“å‡ºæ–‡ä»¶: {output_path}")
        self.logger.info(f"ğŸ¯ TTAæ¨¡å¼: {'å¯ç”¨' if use_tta else 'ç¦ç”¨'}")
        self.logger.info(f"ğŸ“¦ æ‰¹æ¬¡å¤§å°: {batch_size}")

        # å‡†å¤‡æ•°æ®
        datasets, image_paths = self._prepare_test_dataloader(test_dir, use_tta)

        # æ‰§è¡Œé¢„æµ‹
        if use_tta:
            results = self._predict_with_tta(datasets, image_paths, batch_size)
        else:
            results = self._predict_standard(datasets, image_paths, batch_size)

        # åˆ›å»ºæäº¤æ–‡ä»¶
        submission_df = create_submission_file(
            results, output_path, self.idx_to_class
        )

        # é¢„æµ‹ç»Ÿè®¡
        total_time = time.time() - start_time
        self.logger.info(f"ğŸ‰ é¢„æµ‹å®Œæˆ!")
        self.logger.info(f"ğŸ“Š é¢„æµ‹ç»Ÿè®¡:")
        self.logger.info(f"   é¢„æµ‹å›¾åƒæ•°: {len(results)}")
        self.logger.info(f"   å¹³å‡ç½®ä¿¡åº¦: {np.mean([r[2] for r in results]):.4f}")
        self.logger.info(f"   ç½®ä¿¡åº¦æ ‡å‡†å·®: {np.std([r[2] for r in results]):.4f}")
        self.logger.info(f"   é¢„æµ‹ç±»åˆ«æ•°: {len(set(r[1] for r in results))}")
        self.logger.info(f"â±ï¸  æ€»ç”¨æ—¶: {format_time(total_time)}")
        self.logger.info(f"ğŸš€ å¹³å‡é€Ÿåº¦: {len(results)/total_time:.1f} å¼ /ç§’")

        return submission_df

    def predict_single_image(self, image_path: str, 
                           use_tta: bool = False) -> Tuple[int, float, Dict[int, float]]:
        """
        é¢„æµ‹å•å¼ å›¾åƒ

        Args:
            image_path: å›¾åƒè·¯å¾„
            use_tta: æ˜¯å¦ä½¿ç”¨TTA

        Returns:
            predicted_class, confidence, top5_probs
        """
        self.logger.info(f"ğŸ–¼ï¸ é¢„æµ‹å•å¼ å›¾åƒ: {image_path}")

        # åŠ è½½å’Œé¢„å¤„ç†å›¾åƒ
        try:
            image = Image.open(image_path).convert('RGB')
        except Exception as e:
            self.logger.error(f"âŒ å›¾åƒåŠ è½½å¤±è´¥: {e}")
            raise e

        if use_tta:
            # TTAé¢„æµ‹
            transforms_list = get_tta_transforms(
                self.config, self.config['inference'].get('tta_steps', 5)
            )

            all_probs = []
            for transform in transforms_list:
                img_tensor = transform(image).unsqueeze(0)

                with torch.no_grad():
                    logits = self.model(img_tensor.to(self.device))
                    probs = F.softmax(logits, dim=1)
                    all_probs.append(probs.cpu().numpy())

            # å¹³å‡æ¦‚ç‡
            ensemble_probs = np.mean(all_probs, axis=0).flatten()

        else:
            # æ ‡å‡†é¢„æµ‹
            transform = get_test_transforms(self.config)
            img_tensor = transform(image).unsqueeze(0)

            temperature = self.config['model'].get('temperature', 1.0)

            with torch.no_grad():
                logits = self.model(img_tensor.to(self.device))
                if temperature != 1.0:
                    logits = logits / temperature
                probs = F.softmax(logits, dim=1)
                ensemble_probs = probs.cpu().numpy().flatten()

        # è·å–é¢„æµ‹ç»“æœ
        predicted_class = int(np.argmax(ensemble_probs))
        confidence = float(np.max(ensemble_probs))

        # è·å–Top-5æ¦‚ç‡
        top5_indices = np.argsort(ensemble_probs)[-5:][::-1]
        top5_probs = {int(idx): float(ensemble_probs[idx]) for idx in top5_indices}

        # æ—¥å¿—è®°å½•
        class_name = self.idx_to_class.get(predicted_class, f"ç±»åˆ«{predicted_class+1}")
        self.logger.info(f"ğŸ¯ é¢„æµ‹ç»“æœ: {class_name} (ç½®ä¿¡åº¦: {confidence:.4f})")

        return predicted_class, confidence, top5_probs


def main():
    """ä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(description='èŠ±å‰è¯†åˆ«é¢„æµ‹è„šæœ¬ - ä¼˜åŒ–ç‰ˆ')
    parser.add_argument('--config', type=str, default='config.json',
                       help='é…ç½®æ–‡ä»¶è·¯å¾„')
    parser.add_argument('--model_path', type=str, required=True,
                       help='è®­ç»ƒå¥½çš„æ¨¡å‹æƒé‡è·¯å¾„')
    parser.add_argument('--test_dir', type=str, required=True,
                       help='æµ‹è¯•å›¾åƒç›®å½•')
    parser.add_argument('--output', type=str, default='results/submission.csv',
                       help='è¾“å‡ºæ–‡ä»¶è·¯å¾„')
    parser.add_argument('--use_tta', action='store_true',
                       help='ä½¿ç”¨TTA (Test Time Augmentation)')
    parser.add_argument('--batch_size', type=int,
                       help='æ‰¹æ¬¡å¤§å° (è¦†ç›–é…ç½®)')
    parser.add_argument('--single_image', type=str,
                       help='é¢„æµ‹å•å¼ å›¾åƒçš„è·¯å¾„')

    args = parser.parse_args()

    # åŠ è½½é…ç½®
    config = ConfigLoader.load_config(args.config)

    # å‘½ä»¤è¡Œå‚æ•°è¦†ç›–
    if args.batch_size:
        config['inference']['batch_size'] = args.batch_size
    if args.use_tta:
        config['inference']['use_tta'] = True

    # åˆ›å»ºé¢„æµ‹å™¨
    predictor = OptimizedPredictor(config, args.model_path)

    if args.single_image:
        # å•å›¾åƒé¢„æµ‹
        pred_class, confidence, top5_probs = predictor.predict_single_image(
            args.single_image, args.use_tta
        )

        print(f"\nğŸ¯ é¢„æµ‹ç»“æœ:")
        print(f"é¢„æµ‹ç±»åˆ«: {pred_class + 1}")
        print(f"ç½®ä¿¡åº¦: {confidence:.4f}")
        print(f"\nTop-5é¢„æµ‹:")
        for i, (class_idx, prob) in enumerate(top5_probs.items(), 1):
            print(f"{i}. ç±»åˆ«{class_idx + 1}: {prob:.4f}")

    else:
        # æ‰¹é‡é¢„æµ‹
        submission_df = predictor.predict(
            test_dir=args.test_dir,
            output_path=args.output,
            use_tta=args.use_tta,
            batch_size=args.batch_size
        )

        print(f"\nâœ… é¢„æµ‹å®Œæˆï¼Œæäº¤æ–‡ä»¶å·²ä¿å­˜è‡³: {args.output}")


if __name__ == "__main__":
    main()

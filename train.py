"""
èŠ±å‰è¯†åˆ«AIæŒ‘æˆ˜èµ› - è®­ç»ƒè„šæœ¬ (ä¼˜åŒ–ç‰ˆ)
AI Competition Coach - Flower Recognition Challenge Training v1.1.0

ä¼˜åŒ–å†…å®¹:
1. ğŸ·ï¸ æ·»åŠ Label Smoothingæ”¯æŒ
2. ğŸ“ˆ CosineAnnealingWarmRestartså­¦ä¹ ç‡è°ƒåº¦  
3. ğŸ”„ æ¸è¿›å¼è§£å†»è®­ç»ƒç­–ç•¥
4. ğŸ² CutMixå’ŒMixUpæ•°æ®å¢å¼º
5. ğŸŒ¡ï¸ æ¸©åº¦ç¼©æ”¾ä¼˜åŒ–
6. ğŸ“Š å¢å¼ºçš„æŒ‡æ ‡ç›‘æ§å’Œæ—©åœ
7. ğŸ›¡ï¸ æ›´å¼ºçš„é”™è¯¯å¤„ç†å’Œæ¢å¤

ä½¿ç”¨æ–¹æ³•:
python train.py --config config.json --epochs 10
"""

import os
import argparse
import time
import math
from pathlib import Path
from typing import Dict, Tuple, Optional

import torch
import torch.nn as nn
import torch.nn.functional as F
import torch.optim as optim
from torch.utils.tensorboard import SummaryWriter
from torch.optim.lr_scheduler import CosineAnnealingWarmRestarts
from tqdm import tqdm
import warnings
warnings.filterwarnings('ignore')

# å¯¼å…¥è‡ªå®šä¹‰æ¨¡å—
from model import FlowerViTModel, ModelFactory, ModelUtils
from utils import (
    Logger, ConfigLoader, set_seed, create_directories,
    prepare_data_loaders, MetricsCalculator, save_model_checkpoint,
    format_time, LabelSmoothingCrossEntropy, CutMixUp
)


class OptimizedTrainer:
    """ä¼˜åŒ–çš„è®­ç»ƒå™¨ç±»"""

    def __init__(self, config: Dict):
        """
        åˆå§‹åŒ–è®­ç»ƒå™¨

        Args:
            config: é…ç½®å­—å…¸
        """
        self.config = config
        self.logger = Logger(config['paths']['logs_dir'])
        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
        self.best_score = 0.0
        self.patience_counter = 0
        self.epoch_losses = {'train': [], 'val': []}
        self.epoch_metrics = {'train': [], 'val': []}

        # åˆ›å»ºå¿…è¦ç›®å½•
        create_directories(config)

        # è®¾ç½®éšæœºç§å­
        if config.get('reproducibility', {}).get('deterministic', True):
            set_seed(config['reproducibility']['seed'])

        self.logger.info("ğŸš€ ä¼˜åŒ–è®­ç»ƒå™¨åˆå§‹åŒ–å®Œæˆ")

    def setup_model(self) -> nn.Module:
        """è®¾ç½®æ¨¡å‹"""
        model = ModelFactory.create_vit_model(self.config)
        model = model.to(self.device)

        # æ‰“å°æ¨¡å‹ä¿¡æ¯
        ModelUtils.print_model_info(model)

        return model

    def setup_criterion(self) -> nn.Module:
        """è®¾ç½®æŸå¤±å‡½æ•°"""
        label_smoothing = self.config['training'].get('label_smoothing', 0.0)

        if label_smoothing > 0:
            criterion = LabelSmoothingCrossEntropy(
                num_classes=self.config['model']['num_classes'],
                smoothing=label_smoothing
            )
            self.logger.info(f"ğŸ“Š ä½¿ç”¨Label SmoothingæŸå¤±å‡½æ•° (smoothing={label_smoothing})")
        else:
            criterion = nn.CrossEntropyLoss()
            self.logger.info("ğŸ“Š ä½¿ç”¨æ ‡å‡†äº¤å‰ç†µæŸå¤±å‡½æ•°")

        return criterion.to(self.device)

    def setup_optimizer(self, model: nn.Module) -> torch.optim.Optimizer:
        """è®¾ç½®ä¼˜åŒ–å™¨"""
        optimizer_config = self.config['optimizer']
        training_config = self.config['training']

        # åˆ†ç»„å‚æ•°ï¼šbackbone vs åˆ†ç±»å¤´
        backbone_params = []
        classifier_params = []

        for name, param in model.named_parameters():
            if param.requires_grad:
                if 'classifier' in name:
                    classifier_params.append(param)
                else:
                    backbone_params.append(param)

        # ä¸ºbackboneå’Œåˆ†ç±»å¤´è®¾ç½®ä¸åŒå­¦ä¹ ç‡
        param_groups = []
        if backbone_params:
            param_groups.append({
                'params': backbone_params,
                'lr': training_config['learning_rate'] * 0.1,  # backboneç”¨æ›´å°å­¦ä¹ ç‡
                'weight_decay': training_config['weight_decay']
            })
        if classifier_params:
            param_groups.append({
                'params': classifier_params, 
                'lr': training_config['learning_rate'],  # åˆ†ç±»å¤´ç”¨æ ‡å‡†å­¦ä¹ ç‡
                'weight_decay': training_config['weight_decay'] * 0.1
            })

        optimizer = optim.AdamW(
            param_groups,
            betas=optimizer_config['betas'],
            eps=optimizer_config['eps'],
            amsgrad=optimizer_config.get('amsgrad', False)
        )

        self.logger.info(f"âš™ï¸ ä¼˜åŒ–å™¨è®¾ç½®å®Œæˆ")
        self.logger.info(f"   Backboneå­¦ä¹ ç‡: {training_config['learning_rate'] * 0.1}")
        self.logger.info(f"   åˆ†ç±»å¤´å­¦ä¹ ç‡: {training_config['learning_rate']}")

        return optimizer

    def setup_scheduler(self, optimizer: torch.optim.Optimizer) -> torch.optim.lr_scheduler._LRScheduler:
        """è®¾ç½®å­¦ä¹ ç‡è°ƒåº¦å™¨"""
        scheduler_config = self.config['scheduler']

        if scheduler_config['type'] == 'cosine_annealing_warm_restarts':
            scheduler = CosineAnnealingWarmRestarts(
                optimizer,
                T_0=scheduler_config['T_0'],
                T_mult=scheduler_config.get('T_mult', 1),
                eta_min=scheduler_config['eta_min']
            )
            self.logger.info("ğŸ“ˆ ä½¿ç”¨CosineAnnealingWarmRestartsè°ƒåº¦å™¨")
        else:
            scheduler = optim.lr_scheduler.ReduceLROnPlateau(
                optimizer,
                mode='max',
                factor=0.5,
                patience=self.config['training'].get('lr_scheduler_patience', 5),
                verbose=True
            )
            self.logger.info("ğŸ“ˆ ä½¿ç”¨ReduceLROnPlateauè°ƒåº¦å™¨")

        return scheduler

    def train_epoch(self, model: nn.Module, train_loader, criterion: nn.Module, 
                   optimizer: torch.optim.Optimizer, scaler: torch.cuda.amp.GradScaler,
                   epoch: int, cutmix_mixup: Optional[CutMixUp] = None) -> Tuple[float, float]:
        """è®­ç»ƒä¸€ä¸ªepoch"""
        model.train()
        running_loss = 0.0
        correct = 0
        total = 0

        # æ¸è¿›å¼è§£å†»ç­–ç•¥
        if epoch >= 3 and not self.config['model'].get('freeze_backbone', False):
            if epoch == 3:
                model.unfreeze_last_layers(2)  # è§£å†»æœ€å2å±‚
                self.logger.info("ğŸ”“ ç¬¬3è½®ï¼šè§£å†»æœ€å2å±‚")
            elif epoch == 6:
                model.freeze_backbone(False)  # å…¨éƒ¨è§£å†»
                self.logger.info("ğŸ”“ ç¬¬6è½®ï¼šå…¨éƒ¨è§£å†»")

        progress_bar = tqdm(train_loader, desc=f'è®­ç»ƒ Epoch {epoch}', 
                           leave=False, ncols=100)

        for batch_idx, (images, labels) in enumerate(progress_bar):
            images, labels = images.to(self.device), labels.to(self.device)

            labels_a = labels
            labels_b = labels
            lam = 1.0
            # åº”ç”¨CutMix/MixUp
            if cutmix_mixup is not None and torch.rand(1) < 0.5:
                images, labels_a, labels_b, lam = cutmix_mixup(images, labels)

            optimizer.zero_grad()

            # æ··åˆç²¾åº¦è®­ç»ƒ
            with torch.cuda.amp.autocast(enabled=self.config['training']['use_amp']):
                outputs = model(images)

                if cutmix_mixup is not None and torch.rand(1) < 0.5:
                    # CutMixæŸå¤±
                    loss = criterion(outputs, labels_a) * lam + criterion(outputs, labels_b) * (1 - lam)
                else:
                    loss = criterion(outputs, labels)

            # åå‘ä¼ æ’­
            scaler.scale(loss).backward()

            # æ¢¯åº¦è£å‰ª
            if self.config['training'].get('max_grad_norm', 0) > 0:
                scaler.unscale_(optimizer)
                nn.utils.clip_grad_norm_(model.parameters(), 
                                       self.config['training']['max_grad_norm'])

            scaler.step(optimizer)
            scaler.update()

            # ç»Ÿè®¡
            running_loss += loss.item()
            _, predicted = outputs.max(1)
            total += labels.size(0)
            correct += predicted.eq(labels).sum().item()

            # æ›´æ–°è¿›åº¦æ¡
            current_lr = ModelUtils.get_learning_rates(optimizer)[0]
            progress_bar.set_postfix({
                'Loss': f'{loss.item():.4f}',
                'Acc': f'{100.*correct/total:.2f}%',
                'LR': f'{current_lr:.2e}'
            })

        epoch_loss = running_loss / len(train_loader)
        epoch_acc = correct / total

        return epoch_loss, epoch_acc

    def validate_epoch(self, model: nn.Module, val_loader, criterion: nn.Module,
                      metrics_calculator: MetricsCalculator, epoch: int) -> Dict[str, float]:
        """éªŒè¯ä¸€ä¸ªepoch"""
        model.eval()
        running_loss = 0.0
        metrics_calculator.reset()

        progress_bar = tqdm(val_loader, desc=f'éªŒè¯ Epoch {epoch}', 
                           leave=False, ncols=100)

        with torch.no_grad():
            for images, labels in progress_bar:
                images, labels = images.to(self.device), labels.to(self.device)

                outputs = model(images)
                loss = criterion(outputs, labels)

                running_loss += loss.item()

                # æ›´æ–°æŒ‡æ ‡
                probs = F.softmax(outputs, dim=1)
                _, predicted = outputs.max(1)
                metrics_calculator.update(predicted, labels, probs)

                progress_bar.set_postfix({'Loss': f'{loss.item():.4f}'})

        # è®¡ç®—æŒ‡æ ‡
        epoch_loss = running_loss / len(val_loader)
        metrics = metrics_calculator.compute_metrics()

        results = {
            'loss': epoch_loss,
            **metrics
        }

        return results

    def save_checkpoint(self, model: nn.Module, optimizer: torch.optim.Optimizer,
                       scheduler, epoch: int, metrics: Dict[str, float], is_best: bool = False):
        """ä¿å­˜æ£€æŸ¥ç‚¹"""
        checkpoint_info = {
            'epoch': epoch,
            'optimizer_state_dict': optimizer.state_dict(),
            'scheduler_state_dict': scheduler.state_dict(),
            'metrics': metrics,
            'config': self.config,
            'best_score': self.best_score
        }

        save_path = Path(self.config['paths']['checkpoints_dir']) / f'checkpoint_epoch_{epoch}.pth'
        ModelUtils.save_model_weights(model, str(save_path), checkpoint_info)

        if is_best:
            best_path = Path(self.config['paths']['model_dir']) / 'best_model.pth'
            ModelUtils.save_model_weights(model, str(best_path), checkpoint_info)
            self.logger.info(f"ğŸ’¾ æœ€ä½³æ¨¡å‹å·²ä¿å­˜: {best_path}")

    def train(self):
        """ä¸»è®­ç»ƒå¾ªç¯"""
        self.logger.info("ğŸ¯ å¼€å§‹ä¼˜åŒ–è®­ç»ƒæµç¨‹")

        # è®¾ç½®æ¨¡å‹å’Œè®­ç»ƒç»„ä»¶
        model = self.setup_model()
        criterion = self.setup_criterion()
        optimizer = self.setup_optimizer(model)
        scheduler = self.setup_scheduler(optimizer)
        scaler = torch.cuda.amp.GradScaler(enabled=self.config['training']['use_amp'])

        # æ•°æ®åŠ è½½å™¨
        train_loader, val_loader, class_to_idx, idx_to_class = prepare_data_loaders(
            self.config, self.logger)

        # CutMix/MixUp
        cutmix_mixup = None
        if self.config['augmentation'].get('cutmix', {}).get('prob', 0) > 0:
            cutmix_mixup = CutMixUp(
                cutmix_alpha=self.config['augmentation']['cutmix']['alpha'],
                mixup_alpha=self.config['augmentation']['mixup']['alpha'],
                prob=0.5
            )
            self.logger.info("ğŸ² CutMix/MixUpæ•°æ®å¢å¼ºå·²å¯ç”¨")

        # æŒ‡æ ‡è®¡ç®—å™¨
        metrics_calculator = MetricsCalculator(self.config['model']['num_classes'])

        # TensorBoard
        writer = SummaryWriter(self.config['paths']['logs_dir'])

        # è®­ç»ƒå¾ªç¯
        start_time = time.time()
        epochs = self.config['training']['epochs']
        patience = self.config['training']['patience']

        for epoch in range(epochs):
            epoch_start = time.time()

            # è®­ç»ƒ
            train_loss, train_acc = self.train_epoch(
                model, train_loader, criterion, optimizer, scaler, epoch, cutmix_mixup)

            # éªŒè¯
            val_results = self.validate_epoch(
                model, val_loader, criterion, metrics_calculator, epoch)

            # å­¦ä¹ ç‡è°ƒåº¦
            if isinstance(scheduler, CosineAnnealingWarmRestarts):
                scheduler.step()
            else:
                scheduler.step(val_results['competition_score'])

            # è®°å½•æŒ‡æ ‡
            self.epoch_losses['train'].append(train_loss)
            self.epoch_losses['val'].append(val_results['loss'])

            # æ—¥å¿—è®°å½•
            epoch_time = time.time() - epoch_start
            self.logger.info(f"Epoch {epoch+1:2d}/{epochs}")
            self.logger.info(f"  è®­ç»ƒ - Loss: {train_loss:.4f}, Acc: {train_acc:.4f}")
            self.logger.info(f"  éªŒè¯ - Loss: {val_results['loss']:.4f}, Acc: {val_results['accuracy']:.4f}")
            self.logger.info(f"  éªŒè¯ - Top5: {val_results['top5_accuracy']:.4f}, F1: {val_results['f1_macro']:.4f}")
            self.logger.info(f"  ç«èµ›å¾—åˆ†: {val_results['competition_score']:.4f}")
            self.logger.info(f"  ç”¨æ—¶: {format_time(epoch_time)}")

            # TensorBoardè®°å½•
            writer.add_scalar('Loss/Train', train_loss, epoch)
            writer.add_scalar('Loss/Val', val_results['loss'], epoch)
            writer.add_scalar('Accuracy/Train', train_acc, epoch)
            writer.add_scalar('Accuracy/Val', val_results['accuracy'], epoch)
            writer.add_scalar('Top5Accuracy/Val', val_results['top5_accuracy'], epoch)
            writer.add_scalar('F1Macro/Val', val_results['f1_macro'], epoch)
            writer.add_scalar('CompetitionScore/Val', val_results['competition_score'], epoch)
            writer.add_scalar('LearningRate', ModelUtils.get_learning_rates(optimizer)[0], epoch)

            # ä¿å­˜æœ€ä½³æ¨¡å‹
            current_score = val_results['competition_score']
            is_best = current_score > self.best_score

            if is_best:
                self.best_score = current_score
                self.patience_counter = 0
                self.save_checkpoint(model, optimizer, scheduler, epoch, val_results, is_best=True)
            else:
                self.patience_counter += 1

            # æ—©åœæ£€æŸ¥
            if self.patience_counter >= patience:
                self.logger.info(f"â¹ï¸  æ—©åœè§¦å‘ï¼Œå·²ç­‰å¾…{patience}è½®æ— æ”¹å–„")
                break

        # è®­ç»ƒå®Œæˆ
        total_time = time.time() - start_time
        self.logger.info(f"ğŸ‰ è®­ç»ƒå®Œæˆï¼")
        self.logger.info(f"ğŸ“Š æœ€ä½³ç«èµ›å¾—åˆ†: {self.best_score:.4f}")
        self.logger.info(f"â±ï¸  æ€»è®­ç»ƒæ—¶é—´: {format_time(total_time)}")

        writer.close()


def main():
    """ä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(description='èŠ±å‰è¯†åˆ«è®­ç»ƒè„šæœ¬ - ä¼˜åŒ–ç‰ˆ')
    parser.add_argument('--config', type=str, default='config.json',
                       help='é…ç½®æ–‡ä»¶è·¯å¾„')
    parser.add_argument('--epochs', type=int, help='è®­ç»ƒè½®æ•° (è¦†ç›–é…ç½®)')
    parser.add_argument('--batch_size', type=int, help='æ‰¹æ¬¡å¤§å° (è¦†ç›–é…ç½®)')
    parser.add_argument('--lr', type=float, help='å­¦ä¹ ç‡ (è¦†ç›–é…ç½®)')

    args = parser.parse_args()

    # åŠ è½½é…ç½®
    config = ConfigLoader.load_config(args.config)

    # å‘½ä»¤è¡Œå‚æ•°è¦†ç›–
    if args.epochs:
        config['training']['epochs'] = args.epochs
    if args.batch_size:
        config['training']['batch_size'] = args.batch_size
    if args.lr:
        config['training']['learning_rate'] = args.lr

    # å¼€å§‹è®­ç»ƒ
    trainer = OptimizedTrainer(config)
    trainer.train()


if __name__ == "__main__":
    main()

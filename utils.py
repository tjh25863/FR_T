"""
èŠ±å‰è¯†åˆ«AIæŒ‘æˆ˜èµ› - å·¥å…·å‡½æ•°åº“ (ä¿®å¤ç‰ˆ)
AI Competition Coach - Flower Recognition Challenge Utils v1.2.0

ğŸ”§ é‡è¦ä¿®å¤:
1. RandomErasingç§»åŠ¨åˆ°ToTensorä¹‹å
2. ä¿®å¤å¯¼å…¥é”™è¯¯
3. ä¿®å¤æ•°æ®å˜æ¢é¡ºåºé—®é¢˜
4. å¢å¼ºé”™è¯¯å¤„ç†
5. ä¼˜åŒ–å†…å­˜ä½¿ç”¨
"""

import os
import json
import random
import logging
import numpy as np
import pandas as pd
from pathlib import Path
from typing import Dict, List, Tuple, Optional, Union

import matplotlib.pyplot as plt
import seaborn as sns
from collections import defaultdict, Counter

import cv2
from PIL import Image
import torch
import torch.nn as nn
import torch.nn.functional as F
from torch.utils.data import Dataset, DataLoader
import torchvision.transforms as transforms
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score, f1_score, classification_report, confusion_matrix
from tqdm import tqdm
import warnings
warnings.filterwarnings('ignore')

# è®¾ç½®matplotlibä¸­æ–‡å­—ä½“
plt.rcParams['font.sans-serif'] = ['SimHei', 'DejaVu Sans']
plt.rcParams['axes.unicode_minus'] = False

# è®¾ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)


class LabelSmoothingCrossEntropy(nn.Module):
    """
    Label Smoothingäº¤å‰ç†µæŸå¤±å‡½æ•° - ä¿®å¤ç‰ˆ

    æœ‰æ•ˆé™ä½æ¨¡å‹è¿‡æ‹Ÿåˆï¼Œæå‡æ³›åŒ–èƒ½åŠ›ï¼ŒåŒæ—¶æ˜¾è‘—é™ä½Losså€¼
    """

    def __init__(self, num_classes: int, smoothing: float = 0.1):
        """
        Args:
            num_classes: ç±»åˆ«æ•°é‡
            smoothing: å¹³æ»‘å‚æ•° (0.0-1.0)
        """
        super(LabelSmoothingCrossEntropy, self).__init__()
        self.num_classes = num_classes
        self.smoothing = smoothing
        self.confidence = 1.0 - smoothing

    def forward(self, pred: torch.Tensor, target: torch.Tensor) -> torch.Tensor:
        """
        Args:
            pred: é¢„æµ‹logits [batch_size, num_classes]
            target: çœŸå®æ ‡ç­¾ [batch_size]

        Returns:
            smoothed_loss: å¹³æ»‘åçš„æŸå¤±
        """
        pred = F.log_softmax(pred, dim=-1)

        # åˆ›å»ºå¹³æ»‘æ ‡ç­¾
        with torch.no_grad():
            true_dist = torch.zeros_like(pred)
            true_dist.scatter_(1, target.unsqueeze(1), self.confidence)
            true_dist += self.smoothing / self.num_classes

        return torch.mean(torch.sum(-true_dist * pred, dim=-1))


class CutMixUp:
    """
    CutMixå’ŒMixUpæ•°æ®å¢å¼ºå®ç° - ä¿®å¤ç‰ˆ

    ç»“åˆCutMixå’ŒMixUpä¸¤ç§æŠ€æœ¯ï¼Œæå‡æ¨¡å‹æ³›åŒ–èƒ½åŠ›
    """

    def __init__(self, cutmix_alpha: float = 1.0, mixup_alpha: float = 0.2, prob: float = 0.5):
        """
        Args:
            cutmix_alpha: CutMixçš„alphaå‚æ•°
            mixup_alpha: MixUpçš„alphaå‚æ•°  
            prob: ä½¿ç”¨å¢å¼ºçš„æ¦‚ç‡
        """
        self.cutmix_alpha = cutmix_alpha
        self.mixup_alpha = mixup_alpha
        self.prob = prob

    def __call__(self, images: torch.Tensor, labels: torch.Tensor) -> Tuple[torch.Tensor, torch.Tensor, torch.Tensor, float]:
        """
        Args:
            images: è¾“å…¥å›¾åƒ [batch_size, channels, height, width]
            labels: æ ‡ç­¾ [batch_size]

        Returns:
            mixed_images, labels_a, labels_b, lam
        """
        if random.random() > self.prob:
            return images, labels, labels, 1.0

        batch_size = images.size(0)

        # éšæœºé€‰æ‹©CutMixæˆ–MixUp
        if random.random() < 0.5:
            return self._cutmix(images, labels, batch_size)
        else:
            return self._mixup(images, labels, batch_size)

    def _cutmix(self, images: torch.Tensor, labels: torch.Tensor, batch_size: int):
        """CutMixå¢å¼º"""
        indices = torch.randperm(batch_size)
        shuffled_labels = labels[indices]

        lam = np.random.beta(self.cutmix_alpha, self.cutmix_alpha)

        # è®¡ç®—è£å‰ªåŒºåŸŸ
        _, _, H, W = images.shape
        cut_rat = np.sqrt(1. - lam)
        cut_w = int(W * cut_rat)
        cut_h = int(H * cut_rat)

        # éšæœºé€‰æ‹©è£å‰ªä½ç½®
        cx = np.random.randint(W)
        cy = np.random.randint(H)

        bbx1 = np.clip(cx - cut_w // 2, 0, W)
        bby1 = np.clip(cy - cut_h // 2, 0, H)
        bbx2 = np.clip(cx + cut_w // 2, 0, W)
        bby2 = np.clip(cy + cut_h // 2, 0, H)

        # åº”ç”¨è£å‰ª
        mixed_images = images.clone()
        mixed_images[:, :, bby1:bby2, bbx1:bbx2] = images[indices, :, bby1:bby2, bbx1:bbx2]

        # è°ƒæ•´lambda
        lam = 1 - ((bbx2 - bbx1) * (bby2 - bby1) / (W * H))

        return mixed_images, labels, shuffled_labels, lam

    def _mixup(self, images: torch.Tensor, labels: torch.Tensor, batch_size: int):
        """MixUpå¢å¼º"""
        indices = torch.randperm(batch_size)
        shuffled_labels = labels[indices]

        lam = np.random.beta(self.mixup_alpha, self.mixup_alpha)

        mixed_images = lam * images + (1 - lam) * images[indices]

        return mixed_images, labels, shuffled_labels, lam


def set_seed_strict(seed: int = 42):
    """
    æ›´ä¸¥æ ¼çš„éšæœºç§å­è®¾ç½® - ä¿®å¤ç‰ˆ

    Args:
        seed: éšæœºç§å­
    """
    import os

    # è®¾ç½®æ‰€æœ‰éšæœºç§å­
    random.seed(seed)
    np.random.seed(seed)
    torch.manual_seed(seed)
    torch.cuda.manual_seed(seed)
    torch.cuda.manual_seed_all(seed)

    # æ›´ä¸¥æ ¼çš„ç¡®å®šæ€§è®¾ç½®
    torch.backends.cudnn.deterministic = True
    torch.backends.cudnn.benchmark = False
    torch.backends.cudnn.enabled = True

    # è®¾ç½®ç¯å¢ƒå˜é‡
    os.environ['PYTHONHASHSEED'] = str(seed)
    os.environ['CUBLAS_WORKSPACE_CONFIG'] = ':4096:8'

    # PyTorch 1.8+ çš„ç¡®å®šæ€§è®¾ç½®
    try:
        torch.use_deterministic_algorithms(True, warn_only=True)
    except:
        pass

    logger.info(f"ğŸ¯ ä¸¥æ ¼éšæœºç§å­å·²è®¾ç½®: {seed}")


def set_seed(seed: int = 42):
    """æ ‡å‡†éšæœºç§å­è®¾ç½®ï¼ˆä¿æŒå‘åå…¼å®¹ï¼‰"""
    set_seed_strict(seed)


class Logger:
    """å¢å¼ºçš„æ—¥å¿—è®°å½•å™¨ - ä¿®å¤ç‰ˆ"""
    def __init__(self, log_dir: str = './logs', log_level: str = 'INFO'):
        self.log_dir = Path(log_dir)
        self.log_dir.mkdir(parents=True, exist_ok=True)

        # è®¾ç½®æ—¥å¿—æ ¼å¼
        log_format = '%(asctime)s - %(name)s - %(levelname)s - %(message)s'
        date_format = '%Y-%m-%d %H:%M:%S'

        # é…ç½®æ—¥å¿—
        logging.basicConfig(
            level=getattr(logging, log_level.upper()),
            format=log_format,
            datefmt=date_format,
            handlers=[
                logging.FileHandler(self.log_dir / 'training.log', encoding='utf-8'),
                logging.StreamHandler()
            ]
        )

        self.logger = logging.getLogger('FlowerRecognition')
        self.metrics_history = []

    def info(self, message: str):
        self.logger.info(message)

    def warning(self, message: str):
        self.logger.warning(message)

    def error(self, message: str):
        self.logger.error(message)

    def debug(self, message: str):
        self.logger.debug(message)

    def log_metrics(self, epoch: int, metrics: Dict[str, float]):
        """è®°å½•è®­ç»ƒæŒ‡æ ‡"""
        metrics_with_epoch = {'epoch': epoch, **metrics}
        self.metrics_history.append(metrics_with_epoch)

        # ä¿å­˜æŒ‡æ ‡å†å²
        metrics_file = self.log_dir / 'metrics_history.json'
        with open(metrics_file, 'w', encoding='utf-8') as f:
            json.dump(self.metrics_history, f, indent=2, ensure_ascii=False)


class ConfigLoader:
    """é…ç½®æ–‡ä»¶åŠ è½½å™¨ - ä¿®å¤ç‰ˆ"""

    @staticmethod
    def load_config(config_path: str) -> Dict:
        """åŠ è½½å¹¶éªŒè¯é…ç½®æ–‡ä»¶"""
        try:
            with open(config_path, 'r', encoding='utf-8') as f:
                config = json.load(f)

            # åŸºç¡€éªŒè¯
            ConfigLoader._validate_config(config)

            logger.info(f"âœ… é…ç½®æ–‡ä»¶åŠ è½½æˆåŠŸ: {config_path}")
            return config
        except Exception as e:
            logger.error(f"âŒ é…ç½®æ–‡ä»¶åŠ è½½å¤±è´¥: {e}")
            raise ValueError(f"é…ç½®æ–‡ä»¶åŠ è½½å¤±è´¥: {e}")

    @staticmethod
    def _validate_config(config: Dict):
        """éªŒè¯é…ç½®æ–‡ä»¶"""
        required_sections = ['model', 'training', 'data', 'paths']
        for section in required_sections:
            if section not in config:
                raise ValueError(f"é…ç½®æ–‡ä»¶ç¼ºå°‘å¿…éœ€éƒ¨åˆ†: {section}")

    @staticmethod
    def save_config(config: Dict, save_path: str):
        """ä¿å­˜é…ç½®æ–‡ä»¶"""
        Path(save_path).parent.mkdir(parents=True, exist_ok=True)
        with open(save_path, 'w', encoding='utf-8') as f:
            json.dump(config, f, ensure_ascii=False, indent=2)
        logger.info(f"âœ… é…ç½®æ–‡ä»¶å·²ä¿å­˜: {save_path}")


def create_directories(config: Dict):
    """åˆ›å»ºå¿…è¦çš„ç›®å½•"""
    dirs_to_create = [
        config['paths']['model_dir'],
        config['paths']['results_dir'],
        config['paths']['logs_dir'],
        config['paths']['checkpoints_dir']
    ]

    for dir_path in dirs_to_create:
        Path(dir_path).mkdir(parents=True, exist_ok=True)

    logger.info("ğŸ“ å¿…è¦ç›®å½•å·²åˆ›å»º")


def worker_init_fn(worker_id):
    """DataLoader workeråˆå§‹åŒ–å‡½æ•°"""
    worker_seed = torch.initial_seed() % 2**32
    np.random.seed(worker_seed)
    random.seed(worker_seed)



class FlowerDataset(Dataset):
    """èŠ±å‰æ•°æ®é›† - ä¿®å¤ç‰ˆ"""

    def __init__(self, 
                 image_paths: List[str], 
                 labels: Optional[List[int]] = None, 
                 transform: Optional[transforms.Compose] = None, 
                 class_to_idx: Optional[Dict] = None,
                 cache_images: bool = False):
        self.image_paths = image_paths
        self.labels = labels
        self.transform = transform
        self.class_to_idx = class_to_idx
        self.cache_images = cache_images
        self._image_cache = {} if cache_images else None

        if cache_images:
            logger.info("ğŸ—‚ï¸ å¯ç”¨å›¾åƒç¼“å­˜æ¨¡å¼")

    def __len__(self):
        return len(self.image_paths)

    def __getitem__(self, idx):
        # è·å–å›¾åƒ
        image_path = self.image_paths[idx]

        # å°è¯•ä»ç¼“å­˜è·å–
        if self.cache_images and idx in self._image_cache:
            image = self._image_cache[idx].copy()
        else:
            try:
                image = Image.open(image_path).convert('RGB')
                if self.cache_images:
                    self._image_cache[idx] = image.copy()
            except Exception as e:
                logger.warning(f"å›¾åƒåŠ è½½å¤±è´¥: {image_path}, ä½¿ç”¨é»‘è‰²å›¾åƒæ›¿ä»£")
                image = Image.new('RGB', (224, 224), (0, 0, 0))

        # åº”ç”¨æ•°æ®å˜æ¢
        if self.transform:
            try:
                image = self.transform(image)
            except Exception as e:
                logger.error(f"æ•°æ®å˜æ¢å¤±è´¥: {image_path}, é”™è¯¯: {e}")
                # ä½¿ç”¨åŸºç¡€å˜æ¢ä½œä¸ºåå¤‡
                basic_transform = transforms.Compose([
                    transforms.Resize((224, 224)),
                    transforms.ToTensor(),
                    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])
                ])
                image = basic_transform(image)

        if self.labels is not None:
            label = self.labels[idx]
            return image, label
        else:
            # æ¨ç†æ—¶è¿”å›å›¾åƒID
            image_id = Path(image_path).stem
            return image, image_id

    def get_class_distribution(self) -> Dict[int, int]:
        """è·å–ç±»åˆ«åˆ†å¸ƒ"""
        if self.labels is None:
            return {}

        return dict(Counter(self.labels))


def load_class_mappings(mapping_path: str) -> Tuple[Dict[str, int], Dict[int, str]]:
    """
    åŠ è½½ç±»åˆ«æ˜ å°„ - ä¿®å¤ç‰ˆ

    Args:
        mapping_path: æ˜ å°„æ–‡ä»¶è·¯å¾„

    Returns:
        class_to_idx, idx_to_class
    """
    try:
        with open(mapping_path, 'r', encoding='utf-8') as f:
            class_names = json.load(f)

        # å¤„ç†ä¸åŒæ ¼å¼çš„æ˜ å°„æ–‡ä»¶
        if isinstance(class_names, dict):
            # å­—å…¸æ ¼å¼ {"1": "ç±»åˆ«å"}
            idx_to_class = {int(k): v for k, v in class_names.items()}
            class_to_idx = {v: int(k) for k, v in class_names.items()}
        else:
            # åˆ—è¡¨æ ¼å¼
            idx_to_class = {i: name for i, name in enumerate(class_names)}
            class_to_idx = {name: i for i, name in enumerate(class_names)}

        logger.info(f"âœ… ç±»åˆ«æ˜ å°„åŠ è½½æˆåŠŸ: {len(class_to_idx)} ä¸ªç±»åˆ«")
        return class_to_idx, idx_to_class
    except Exception as e:
        logger.error(f"âŒ ç±»åˆ«æ˜ å°„åŠ è½½å¤±è´¥: {e}")
        # åˆ›å»ºé»˜è®¤æ˜ å°„
        idx_to_class = {i: f'class_{i+1}' for i in range(100)}
        class_to_idx = {f'class_{i+1}': i for i in range(100)}
        return class_to_idx, idx_to_class


def get_train_transforms_fixed(config: Dict) -> transforms.Compose:
    """
    ğŸ”§ ä¿®å¤ç‰ˆï¼šè·å–è®­ç»ƒæ•°æ®å˜æ¢ï¼ˆä¿®å¤RandomErasingä½ç½®ï¼‰

    ä¸»è¦ä¿®å¤ï¼š
    1. å°†RandomErasingç§»åŠ¨åˆ°ToTensor()ä¹‹å
    2. ç¡®ä¿æ‰€æœ‰å˜æ¢çš„æ­£ç¡®é¡ºåº
    3. æ›´ä¿å®ˆçš„å¢å¼ºå‚æ•°

    Args:
        config: é…ç½®å­—å…¸
    Returns:
        æ•°æ®å˜æ¢åºåˆ—
    """
    aug_config = config['augmentation']

    # Step 1: PILå›¾åƒå˜æ¢ï¼ˆåœ¨ToTensorä¹‹å‰ï¼‰
    pil_transforms = [
        transforms.Resize(tuple(aug_config['resize'])),

        transforms.RandomResizedCrop(
            aug_config['resize'][0], 
            scale=tuple(aug_config['random_crop']['scale']),    # [0.90, 1.0]
            ratio=tuple(aug_config['random_crop']['ratio'])     # [0.85, 1.15]
        ),

        transforms.RandomHorizontalFlip(aug_config['horizontal_flip']),  # 0.3
        transforms.RandomRotation(aug_config['rotation']),  # 8åº¦

        transforms.ColorJitter(
            brightness=aug_config['color_jitter']['brightness'],  # 0.15
            contrast=aug_config['color_jitter']['contrast'],      # 0.15
            saturation=aug_config['color_jitter']['saturation'],  # 0.15
            hue=aug_config['color_jitter']['hue']                 # 0.05
        ),
    ]

    # Step 2: è½¬æ¢ä¸ºå¼ é‡
    tensor_conversion = [
        transforms.ToTensor(),
    ]

    # Step 3: å¼ é‡å˜æ¢ï¼ˆåœ¨ToTensorä¹‹åï¼‰
    tensor_transforms = [
        # âœ… RandomErasingç°åœ¨åœ¨æ­£ç¡®ä½ç½®ï¼ˆToTensorä¹‹åï¼‰
        transforms.RandomErasing(
            p=0.1,               # 10%æ¦‚ç‡åº”ç”¨
            scale=(0.02, 0.08),  # æ›´å°çš„æ“¦é™¤åŒºåŸŸ
            ratio=(0.3, 3.3),    # æ“¦é™¤åŒºåŸŸå®½é«˜æ¯”
            value=0,             # æ“¦é™¤å€¼
            inplace=False        # ä¸åŸåœ°æ“ä½œ
        ),

        transforms.Normalize(
            mean=aug_config['normalize']['mean'],
            std=aug_config['normalize']['std']
        )
    ]

    # åˆå¹¶æ‰€æœ‰å˜æ¢
    all_transforms = pil_transforms + tensor_conversion + tensor_transforms

    return transforms.Compose(all_transforms)


def get_train_transforms_safe(config: Dict) -> transforms.Compose:
    """
    ğŸ›¡ï¸ å®‰å…¨ç‰ˆï¼šè·å–è®­ç»ƒæ•°æ®å˜æ¢ï¼ˆç§»é™¤RandomErasingï¼‰

    Args:
        config: é…ç½®å­—å…¸
    Returns:
        æ•°æ®å˜æ¢åºåˆ—
    """
    aug_config = config['augmentation']

    transform_list = [
        # PILå˜æ¢
        transforms.Resize(tuple(aug_config['resize'])),
        transforms.RandomResizedCrop(
            aug_config['resize'][0], 
            scale=tuple(aug_config['random_crop']['scale']),
            ratio=tuple(aug_config['random_crop']['ratio'])
        ),
        transforms.RandomHorizontalFlip(aug_config['horizontal_flip']),
        transforms.RandomRotation(aug_config['rotation']),
        transforms.ColorJitter(
            brightness=aug_config['color_jitter']['brightness'],
            contrast=aug_config['color_jitter']['contrast'],
            saturation=aug_config['color_jitter']['saturation'],
            hue=aug_config['color_jitter']['hue']
        ),

        # è½¬æ¢å’Œå½’ä¸€åŒ–
        transforms.ToTensor(),
        transforms.Normalize(
            mean=aug_config['normalize']['mean'],
            std=aug_config['normalize']['std']
        )
    ]

    return transforms.Compose(transform_list)


def get_val_transforms(config: Dict) -> transforms.Compose:
    """è·å–éªŒè¯æ•°æ®å˜æ¢"""
    aug_config = config['augmentation']

    transform_list = [
        transforms.Resize(tuple(aug_config['resize'])),
        transforms.CenterCrop(aug_config['resize'][0]),
        transforms.ToTensor(),
        transforms.Normalize(
            mean=aug_config['normalize']['mean'],
            std=aug_config['normalize']['std']
        )
    ]

    return transforms.Compose(transform_list)


def get_test_transforms(config: Dict) -> transforms.Compose:
    """è·å–æµ‹è¯•æ•°æ®å˜æ¢"""
    return get_val_transforms(config)


def get_tta_transforms(config: Dict, num_augmentations: int = 5) -> List[transforms.Compose]:
    """
    è·å–TTA (Test Time Augmentation) å˜æ¢åˆ—è¡¨

    Args:
        config: é…ç½®å­—å…¸
        num_augmentations: å¢å¼ºæ•°é‡

    Returns:
        å˜æ¢åˆ—è¡¨
    """
    aug_config = config['augmentation']
    base_size = aug_config['resize'][0]

    tta_transforms = []

    # 1. ä¸­å¿ƒè£å‰ªï¼ˆåŸå›¾ï¼‰
    tta_transforms.append(transforms.Compose([
        transforms.Resize((base_size, base_size)),
        transforms.CenterCrop(base_size),
        transforms.ToTensor(),
        transforms.Normalize(
            mean=aug_config['normalize']['mean'],
            std=aug_config['normalize']['std']
        )
    ]))

    # 2. ç¨å¤§å°ºå¯¸ + ä¸­å¿ƒè£å‰ª
    if len(tta_transforms) < num_augmentations:
        tta_transforms.append(transforms.Compose([
            transforms.Resize((int(base_size * 1.1), int(base_size * 1.1))),
            transforms.CenterCrop(base_size),
            transforms.ToTensor(),
            transforms.Normalize(
                mean=aug_config['normalize']['mean'],
                std=aug_config['normalize']['std']
            )
        ]))

    # 3. æ°´å¹³ç¿»è½¬
    if len(tta_transforms) < num_augmentations:
        tta_transforms.append(transforms.Compose([
            transforms.Resize((base_size, base_size)),
            transforms.CenterCrop(base_size),
            transforms.RandomHorizontalFlip(p=1.0),
            transforms.ToTensor(),
            transforms.Normalize(
                mean=aug_config['normalize']['mean'],
                std=aug_config['normalize']['std']
            )
        ]))

    # 4. å¤šå°ºåº¦æµ‹è¯•1
    if len(tta_transforms) < num_augmentations:
        tta_transforms.append(transforms.Compose([
            transforms.Resize((int(base_size * 0.9), int(base_size * 0.9))),
            transforms.CenterCrop(base_size),
            transforms.ToTensor(),
            transforms.Normalize(
                mean=aug_config['normalize']['mean'],
                std=aug_config['normalize']['std']
            )
        ]))

    # 5. å¤šå°ºåº¦æµ‹è¯•2
    if len(tta_transforms) < num_augmentations:
        tta_transforms.append(transforms.Compose([
            transforms.Resize((int(base_size * 1.15), int(base_size * 1.15))),
            transforms.CenterCrop(base_size),
            transforms.ToTensor(),
            transforms.Normalize(
                mean=aug_config['normalize']['mean'],
                std=aug_config['normalize']['std']
            )
        ]))

    return tta_transforms[:num_augmentations]


def prepare_data_loaders(config: Dict, logger: Logger) -> Tuple[DataLoader, DataLoader, Dict, Dict]:
    """
    å‡†å¤‡æ•°æ®åŠ è½½å™¨ - ä¿®å¤ç‰ˆ

    Args:
        config: é…ç½®å­—å…¸
        logger: æ—¥å¿—è®°å½•å™¨

    Returns:
        train_loader, val_loader, class_to_idx, idx_to_class
    """
    logger.info("ğŸš€ å¼€å§‹å‡†å¤‡ä¿®å¤ç‰ˆæ•°æ®åŠ è½½å™¨...")

    # åŠ è½½ç±»åˆ«æ˜ å°„
    class_to_idx, idx_to_class = load_class_mappings(config['data']['class_mapping'])

    # æ”¶é›†è®­ç»ƒæ•°æ®
    train_dir = Path(config['data']['train_dir'])
    image_paths = []
    labels = []

    for class_dir in sorted(train_dir.iterdir()):
        if class_dir.is_dir():
            class_name = class_dir.name
            try:
                class_idx = int(class_name) - 1  # 1-100 -> 0-99
                if 0 <= class_idx < 100:
                    # æ”¶é›†è¯¥ç±»åˆ«çš„æ‰€æœ‰å›¾åƒ
                    valid_extensions = {'.jpg', '.jpeg', '.png', '.bmp', '.tiff', '.JPG', '.JPEG', '.PNG'}
                    for ext in valid_extensions:
                        for img_path in class_dir.glob(f'*{ext}'):
                            if img_path.is_file():  # ç¡®ä¿æ˜¯æ–‡ä»¶
                                image_paths.append(str(img_path))
                                labels.append(class_idx)
                else:
                    logger.warning(f"è·³è¿‡æ— æ•ˆç±»åˆ«: {class_name}")
            except ValueError:
                logger.warning(f"è·³è¿‡éæ•°å­—ç±»åˆ«: {class_name}")

    logger.info(f"ğŸ“Š æ€»å…±æ‰¾åˆ° {len(image_paths)} å¼ è®­ç»ƒå›¾åƒ")

    if len(image_paths) == 0:
        raise ValueError("æ²¡æœ‰æ‰¾åˆ°æœ‰æ•ˆçš„è®­ç»ƒå›¾åƒï¼Œè¯·æ£€æŸ¥æ•°æ®ç›®å½•è·¯å¾„")

    # åˆ†ææ•°æ®åˆ†å¸ƒ
    label_counts = Counter(labels)
    logger.info(f"ğŸ“ˆ ç±»åˆ«åˆ†å¸ƒç»Ÿè®¡:")
    logger.info(f"   æœ€å¤šç±»åˆ«: {max(label_counts.values())} å¼ å›¾åƒ")
    logger.info(f"   æœ€å°‘ç±»åˆ«: {min(label_counts.values())} å¼ å›¾åƒ")
    logger.info(f"   å¹³å‡æ¯ç±»: {len(image_paths) / len(label_counts):.1f} å¼ å›¾åƒ")

    # åˆ†å±‚åˆ’åˆ†è®­ç»ƒéªŒè¯é›†
    try:
        train_paths, val_paths, train_labels, val_labels = train_test_split(
            image_paths, labels, 
            test_size=config['data']['val_split'],
            random_state=config.get('reproducibility', {}).get('seed', 42),
            stratify=labels
        )
    except Exception as e:
        logger.warning(f"åˆ†å±‚åˆ’åˆ†å¤±è´¥ï¼Œä½¿ç”¨éšæœºåˆ’åˆ†: {e}")
        train_paths, val_paths, train_labels, val_labels = train_test_split(
            image_paths, labels, 
            test_size=config['data']['val_split'],
            random_state=config.get('reproducibility', {}).get('seed', 42)
        )

    logger.info(f"ğŸ“Š æ•°æ®åˆ’åˆ†å®Œæˆ:")
    logger.info(f"   è®­ç»ƒé›†: {len(train_paths)} å¼ å›¾åƒ")
    logger.info(f"   éªŒè¯é›†: {len(val_paths)} å¼ å›¾åƒ")

    # åˆ›å»ºæ•°æ®å˜æ¢ - ä½¿ç”¨ä¿®å¤ç‰ˆæœ¬
    try:
        train_transform = get_train_transforms_fixed(config)
        logger.info("âœ… ä½¿ç”¨ä¿®å¤ç‰ˆè®­ç»ƒå˜æ¢ï¼ˆåŒ…å«RandomErasingï¼‰")
    except Exception as e:
        logger.warning(f"ä¿®å¤ç‰ˆå˜æ¢åˆ›å»ºå¤±è´¥ï¼Œä½¿ç”¨å®‰å…¨ç‰ˆæœ¬: {e}")
        train_transform = get_train_transforms_safe(config)
        logger.info("ğŸ›¡ï¸ ä½¿ç”¨å®‰å…¨ç‰ˆè®­ç»ƒå˜æ¢ï¼ˆç§»é™¤RandomErasingï¼‰")

    val_transform = get_val_transforms(config)

    # åˆ›å»ºæ•°æ®é›†
    cache_images = config['data'].get('cache_images', False)
    train_dataset = FlowerDataset(train_paths, train_labels, train_transform, cache_images=cache_images)
    val_dataset = FlowerDataset(val_paths, val_labels, val_transform)

    # åˆ›å»ºæ•°æ®åŠ è½½å™¨
    num_workers = min(config['data']['num_workers'], os.cpu_count() or 4)

    train_loader = DataLoader(
        train_dataset,
        batch_size=config['training']['batch_size'],
        shuffle=True,
        num_workers=num_workers,
        pin_memory=config['data']['pin_memory'],
        drop_last=True,
        persistent_workers=config['data'].get('persistent_workers', False),
        worker_init_fn=worker_init_fn,
        generator=torch.Generator().manual_seed(config.get('reproducibility', {}).get('seed', 42))
    )

    val_loader = DataLoader(
        val_dataset,
        batch_size=config['training']['batch_size'],
        shuffle=False,
        num_workers=num_workers,
        pin_memory=config['data']['pin_memory'],
        persistent_workers=config['data'].get('persistent_workers', False)
    )

    logger.info("âœ… ä¿®å¤ç‰ˆæ•°æ®åŠ è½½å™¨å‡†å¤‡å®Œæˆ")
    return train_loader, val_loader, class_to_idx, idx_to_class



class MetricsCalculator:
    """ä¼˜åŒ–çš„æŒ‡æ ‡è®¡ç®—å™¨ - ä¿®å¤ç‰ˆ"""

    def __init__(self, num_classes: int = 100, device: str = 'cpu'):
        self.num_classes = num_classes
        self.device = device
        self.reset()

    def reset(self):
        """é‡ç½®æ‰€æœ‰ç´¯ç§¯çš„æŒ‡æ ‡"""
        self.all_preds = []
        self.all_labels = []  
        self.all_probs = []
        self.all_confidences = []

    def update(self, preds: torch.Tensor, labels: torch.Tensor, probs: torch.Tensor):
        """æ›´æ–°æŒ‡æ ‡"""
        # ç§»åˆ°CPUè¿›è¡Œè®¡ç®—
        preds = preds.cpu().numpy()
        labels = labels.cpu().numpy()
        probs = probs.cpu().numpy()

        self.all_preds.extend(preds)
        self.all_labels.extend(labels)
        self.all_probs.extend(probs)

        # è®¡ç®—é¢„æµ‹ç½®ä¿¡åº¦
        max_probs = np.max(probs, axis=1)
        self.all_confidences.extend(max_probs)

    def compute_metrics(self) -> Dict[str, float]:
        """è®¡ç®—æ‰€æœ‰æŒ‡æ ‡"""
        preds = np.array(self.all_preds)
        labels = np.array(self.all_labels)
        probs = np.array(self.all_probs)
        confidences = np.array(self.all_confidences)

        # åŸºç¡€æŒ‡æ ‡
        top1_acc = accuracy_score(labels, preds)
        top5_acc = self._calculate_topk_accuracy(probs, labels, k=5)
        f1_macro = f1_score(labels, preds, average='macro', zero_division=0)

        # ç½®ä¿¡åº¦ç»Ÿè®¡
        mean_confidence = np.mean(confidences)
        confidence_std = np.std(confidences)

        # æ ¡å‡†è¯¯å·® (Expected Calibration Error)
        ece = self._calculate_ece(probs, labels, preds)

        # ç«èµ›ç»¼åˆå¾—åˆ† (70% Top-1 + 20% Top-5 + 10% F1)
        competition_score = 0.7 * top1_acc + 0.2 * top5_acc + 0.1 * f1_macro

        metrics = {
            'accuracy': top1_acc,
            'top5_accuracy': top5_acc,
            'f1_macro': f1_macro,
            'competition_score': competition_score,
            'mean_confidence': mean_confidence,
            'confidence_std': confidence_std,
            'expected_calibration_error': ece
        }

        return metrics

    def _calculate_topk_accuracy(self, probs: np.ndarray, labels: np.ndarray, k: int = 5) -> float:
        """è®¡ç®—Top-Kå‡†ç¡®ç‡"""
        topk_preds = np.argsort(probs, axis=1)[:, -k:]

        correct = 0
        for i, label in enumerate(labels):
            if label in topk_preds[i]:
                correct += 1

        return correct / len(labels)

    def _calculate_ece(self, probs: np.ndarray, labels: np.ndarray, preds: np.ndarray, n_bins: int = 15) -> float:
        """è®¡ç®—æœŸæœ›æ ¡å‡†è¯¯å·® (Expected Calibration Error)"""
        confidences = np.max(probs, axis=1)
        accuracies = (preds == labels).astype(float)

        bin_boundaries = np.linspace(0, 1, n_bins + 1)
        bin_lowers = bin_boundaries[:-1]
        bin_uppers = bin_boundaries[1:]

        ece = 0
        for bin_lower, bin_upper in zip(bin_lowers, bin_uppers):
            in_bin = (confidences > bin_lower) & (confidences <= bin_upper)
            prop_in_bin = in_bin.mean()

            if prop_in_bin > 0:
                accuracy_in_bin = accuracies[in_bin].mean()
                avg_confidence_in_bin = confidences[in_bin].mean()
                ece += np.abs(avg_confidence_in_bin - accuracy_in_bin) * prop_in_bin

        return ece

    def get_confusion_matrix(self) -> np.ndarray:
        """è·å–æ··æ·†çŸ©é˜µ"""
        return confusion_matrix(self.all_labels, self.all_preds)

    def get_classification_report(self) -> str:
        """è·å–åˆ†ç±»æŠ¥å‘Š"""
        return classification_report(self.all_labels, self.all_preds, zero_division=0)

    def get_per_class_metrics(self) -> Dict[int, Dict[str, float]]:
        """è·å–æ¯ä¸ªç±»åˆ«çš„è¯¦ç»†æŒ‡æ ‡"""
        from sklearn.metrics import precision_recall_fscore_support

        precision, recall, f1, support = precision_recall_fscore_support(
            self.all_labels, self.all_preds, average=None, zero_division=0
        )

        per_class_metrics = {}
        for i in range(len(precision)):
            per_class_metrics[i] = {
                'precision': precision[i],
                'recall': recall[i], 
                'f1': f1[i],
                'support': support[i]
            }

        return per_class_metrics


def save_model_checkpoint(model: nn.Module, optimizer: torch.optim.Optimizer, 
                         scheduler, epoch: int, metrics: Dict[str, float], 
                         config: Dict, save_path: str, is_best: bool = False):
    """
    ä¿å­˜æ¨¡å‹æ£€æŸ¥ç‚¹ - ä¿®å¤ç‰ˆ
    """
    checkpoint = {
        'epoch': epoch,
        'model_state_dict': model.state_dict(),
        'optimizer_state_dict': optimizer.state_dict(),
        'scheduler_state_dict': scheduler.state_dict() if scheduler else None,
        'metrics': metrics,
        'config': config,
        'model_info': {
            'total_params': sum(p.numel() for p in model.parameters()),
            'trainable_params': sum(p.numel() for p in model.parameters() if p.requires_grad)
        }
    }

    # åˆ›å»ºä¿å­˜ç›®å½•
    Path(save_path).parent.mkdir(parents=True, exist_ok=True)

    # ä¿å­˜æ£€æŸ¥ç‚¹
    torch.save(checkpoint, save_path)

    if is_best:
        best_path = Path(save_path).parent / 'best_model.pth'
        torch.save(checkpoint, best_path)
        logger.info(f"ğŸ’¾ æœ€ä½³æ¨¡å‹å·²ä¿å­˜: {best_path}")

    logger.info(f"âœ… æ£€æŸ¥ç‚¹å·²ä¿å­˜: {save_path}")


def visualize_training_history_enhanced(history: Dict[str, List[float]], save_path: str = None):
    """
    å¢å¼ºçš„è®­ç»ƒå†å²å¯è§†åŒ– - ä¿®å¤ç‰ˆ

    Args:
        history: è®­ç»ƒå†å²å­—å…¸
        save_path: ä¿å­˜è·¯å¾„
    """
    try:
        fig, axes = plt.subplots(2, 3, figsize=(18, 12))

        # æŸå¤±æ›²çº¿
        if 'train_loss' in history and 'val_loss' in history:
            axes[0, 0].plot(history['train_loss'], label='è®­ç»ƒæŸå¤±', linewidth=2)
            axes[0, 0].plot(history['val_loss'], label='éªŒè¯æŸå¤±', linewidth=2)
            axes[0, 0].set_title('æŸå¤±æ›²çº¿', fontsize=14, fontweight='bold')
            axes[0, 0].set_xlabel('Epoch')
            axes[0, 0].set_ylabel('Loss')
            axes[0, 0].legend()
            axes[0, 0].grid(True, alpha=0.3)

        # å‡†ç¡®ç‡æ›²çº¿
        if 'train_acc' in history and 'val_acc' in history:
            axes[0, 1].plot(history['train_acc'], label='è®­ç»ƒå‡†ç¡®ç‡', linewidth=2)
            axes[0, 1].plot(history['val_acc'], label='éªŒè¯å‡†ç¡®ç‡', linewidth=2)
            axes[0, 1].set_title('å‡†ç¡®ç‡æ›²çº¿', fontsize=14, fontweight='bold')
            axes[0, 1].set_xlabel('Epoch')
            axes[0, 1].set_ylabel('Accuracy')
            axes[0, 1].legend()
            axes[0, 1].grid(True, alpha=0.3)

        # Top-5å‡†ç¡®ç‡
        if 'val_top5_acc' in history:
            axes[0, 2].plot(history['val_top5_acc'], label='Top-5å‡†ç¡®ç‡', color='green', linewidth=2)
            axes[0, 2].set_title('Top-5å‡†ç¡®ç‡', fontsize=14, fontweight='bold')
            axes[0, 2].set_xlabel('Epoch')
            axes[0, 2].set_ylabel('Top-5 Accuracy')
            axes[0, 2].legend()
            axes[0, 2].grid(True, alpha=0.3)

        # ç«èµ›å¾—åˆ†
        if 'val_competition_score' in history:
            axes[1, 0].plot(history['val_competition_score'], label='ç«èµ›å¾—åˆ†', color='red', linewidth=2)
            axes[1, 0].set_title('ç«èµ›ç»¼åˆå¾—åˆ†', fontsize=14, fontweight='bold')
            axes[1, 0].set_xlabel('Epoch')
            axes[1, 0].set_ylabel('Competition Score')
            axes[1, 0].legend()
            axes[1, 0].grid(True, alpha=0.3)

        # F1åˆ†æ•°
        if 'val_f1_macro' in history:
            axes[1, 1].plot(history['val_f1_macro'], label='F1å®å¹³å‡', color='purple', linewidth=2)
            axes[1, 1].set_title('F1å®å¹³å‡åˆ†æ•°', fontsize=14, fontweight='bold')
            axes[1, 1].set_xlabel('Epoch')
            axes[1, 1].set_ylabel('F1 Macro')
            axes[1, 1].legend()
            axes[1, 1].grid(True, alpha=0.3)

        # ç½®ä¿¡åº¦ç»Ÿè®¡
        if 'val_mean_confidence' in history:
            axes[1, 2].plot(history['val_mean_confidence'], label='å¹³å‡ç½®ä¿¡åº¦', color='orange', linewidth=2)
            if 'val_expected_calibration_error' in history:
                ax2 = axes[1, 2].twinx()
                ax2.plot(history['val_expected_calibration_error'], 
                        label='æ ¡å‡†è¯¯å·®', color='brown', linewidth=2, linestyle='--')
                ax2.set_ylabel('ECE')
                ax2.legend(loc='upper right')
            axes[1, 2].set_title('æ¨¡å‹æ ¡å‡†åº¦', fontsize=14, fontweight='bold')
            axes[1, 2].set_xlabel('Epoch')
            axes[1, 2].set_ylabel('Mean Confidence')
            axes[1, 2].legend(loc='upper left')
            axes[1, 2].grid(True, alpha=0.3)

        plt.tight_layout()

        if save_path:
            plt.savefig(save_path, dpi=300, bbox_inches='tight')
            logger.info(f"ğŸ“Š è®­ç»ƒå†å²å›¾è¡¨å·²ä¿å­˜: {save_path}")

        plt.show()
    except Exception as e:
        logger.error(f"å¯è§†åŒ–å¤±è´¥: {e}")


def plot_confusion_matrix(cm: np.ndarray, class_names: List[str] = None, 
                         save_path: str = None, normalize: bool = True):
    """
    ç»˜åˆ¶æ··æ·†çŸ©é˜µ - ä¿®å¤ç‰ˆ

    Args:
        cm: æ··æ·†çŸ©é˜µ
        class_names: ç±»åˆ«åç§°åˆ—è¡¨
        save_path: ä¿å­˜è·¯å¾„
        normalize: æ˜¯å¦å½’ä¸€åŒ–
    """
    try:
        if normalize:
            cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]
            title = 'å½’ä¸€åŒ–æ··æ·†çŸ©é˜µ'
            fmt = '.2f'
        else:
            title = 'æ··æ·†çŸ©é˜µ'
            fmt = 'd'

        plt.figure(figsize=(12, 10))

        # åªæ˜¾ç¤ºå‰20ä¸ªç±»åˆ«ï¼Œé¿å…å›¾è¡¨è¿‡å¤§
        display_size = min(20, cm.shape[0])
        cm_display = cm[:display_size, :display_size]

        sns.heatmap(cm_display, 
                    annot=True, 
                    fmt=fmt, 
                    cmap='Blues',
                    xticklabels=class_names[:display_size] if class_names else range(display_size),
                    yticklabels=class_names[:display_size] if class_names else range(display_size))

        plt.title(f'{title} (å‰{display_size}ä¸ªç±»åˆ«)', fontsize=16, fontweight='bold')
        plt.ylabel('çœŸå®æ ‡ç­¾', fontsize=12)
        plt.xlabel('é¢„æµ‹æ ‡ç­¾', fontsize=12)
        plt.xticks(rotation=45)
        plt.yticks(rotation=0)

        if save_path:
            plt.savefig(save_path, dpi=300, bbox_inches='tight')
            logger.info(f"ğŸ“Š æ··æ·†çŸ©é˜µå·²ä¿å­˜: {save_path}")

        plt.show()
    except Exception as e:
        logger.error(f"æ··æ·†çŸ©é˜µç»˜åˆ¶å¤±è´¥: {e}")


def create_submission_file(predictions: List[Tuple[str, int, float]], 
                          output_path: str, 
                          class_mapping: Dict[int, str] = None):
    """
    åˆ›å»ºç«èµ›æäº¤æ–‡ä»¶ - ä¿®å¤ç‰ˆ

    Args:
        predictions: é¢„æµ‹ç»“æœåˆ—è¡¨ [(image_id, pred_class, confidence), ...]
        output_path: è¾“å‡ºè·¯å¾„
        class_mapping: ç±»åˆ«æ˜ å°„å­—å…¸
    """
    df_data = []

    for result in predictions:
        if len(result) == 3:
            image_id, pred_class, confidence = result
        else:
            image_id, pred_class = result
            confidence = 1.0

        # è½¬æ¢æ ‡ç­¾æ ¼å¼
        if class_mapping and pred_class in class_mapping:
            label = class_mapping[pred_class]
        else:
            label = str(pred_class + 1)  # 0-99 -> 1-100

        df_data.append({
            'img_name': image_id,
            'predicted_class': label,
            'confidence': confidence
        })

    # åˆ›å»ºDataFrameå¹¶ä¿å­˜
    df = pd.DataFrame(df_data)

    # ç¡®ä¿ç›®å½•å­˜åœ¨
    Path(output_path).parent.mkdir(parents=True, exist_ok=True)

    # ä¿å­˜ä¸ºCSVï¼ˆä¸åŒ…å«ç´¢å¼•ï¼‰
    df.to_csv(output_path, index=False, encoding='utf-8')

    logger.info(f"âœ… æäº¤æ–‡ä»¶å·²ä¿å­˜: {output_path}")
    logger.info(f"ğŸ“Š æäº¤ç»Ÿè®¡:")
    logger.info(f"   æ€»é¢„æµ‹æ•°: {len(df)} ä¸ª")
    logger.info(f"   å¹³å‡ç½®ä¿¡åº¦: {df['confidence'].mean():.4f}")
    logger.info(f"   é¢„æµ‹ç±»åˆ«æ•°: {df['predicted_class'].nunique()} ä¸ª")

    return df


def format_time(seconds: float) -> str:
    """æ ¼å¼åŒ–æ—¶é—´æ˜¾ç¤º"""
    if seconds < 60:
        return f"{seconds:.2f} ç§’"
    elif seconds < 3600:
        minutes = seconds // 60
        seconds = seconds % 60
        return f"{int(minutes)} åˆ† {seconds:.1f} ç§’"
    else:
        hours = seconds // 3600
        minutes = (seconds % 3600) // 60
        seconds = seconds % 60
        return f"{int(hours)} æ—¶ {int(minutes)} åˆ† {seconds:.1f} ç§’"


def print_model_summary(model: nn.Module, input_size: Tuple[int, int, int] = (3, 224, 224)):
    """
    æ‰“å°æ¨¡å‹æ‘˜è¦ä¿¡æ¯ - ä¿®å¤ç‰ˆ

    Args:
        model: æ¨¡å‹
        input_size: è¾“å…¥å°ºå¯¸
    """
    try:
        # è®¡ç®—å‚æ•°é‡
        total_params = sum(p.numel() for p in model.parameters())
        trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)

        logger.info("ğŸ“Š æ¨¡å‹æ‘˜è¦ä¿¡æ¯:")
        logger.info("="*50)
        logger.info(f"ğŸ“Š æ€»å‚æ•°é‡: {total_params:,}")
        logger.info(f"ğŸ“Š å¯è®­ç»ƒå‚æ•°: {trainable_params:,}")
        logger.info(f"ğŸ“Š å†»ç»“å‚æ•°: {total_params - trainable_params:,}")
        logger.info(f"ğŸ“Š æ¨¡å‹å¤§å°: {total_params * 4 / 1024 / 1024:.2f} MB")
        logger.info(f"ğŸ“Š å¯è®­ç»ƒæ¯”ä¾‹: {trainable_params / total_params:.2%}")

        # æµ‹è¯•æ¨ç†æ—¶é—´
        device = next(model.parameters()).device
        model.eval()

        dummy_input = torch.randn(1, *input_size).to(device)

        # é¢„çƒ­
        with torch.no_grad():
            for _ in range(10):
                _ = model(dummy_input)

        # æµ‹è¯•æ¨ç†é€Ÿåº¦
        import time
        if device.type == 'cuda':
            torch.cuda.synchronize()

        start_time = time.time()
        with torch.no_grad():
            for _ in range(100):
                _ = model(dummy_input)

        if device.type == 'cuda':
            torch.cuda.synchronize()
        end_time = time.time()

        avg_inference_time = (end_time - start_time) / 100 * 1000  # è½¬æ¢ä¸ºæ¯«ç§’
        logger.info(f"ğŸ“Š å¹³å‡æ¨ç†æ—¶é—´: {avg_inference_time:.2f} ms")
        logger.info(f"ğŸ“Š æ¨ç†FPS: {1000/avg_inference_time:.1f}")
        logger.info("="*50)
    except Exception as e:
        logger.error(f"æ¨¡å‹æ‘˜è¦ç”Ÿæˆå¤±è´¥: {e}")


# å¯¼å‡ºä¸»è¦å‡½æ•°
__all__ = [
    'LabelSmoothingCrossEntropy',
    'CutMixUp', 
    'set_seed_strict',
    'set_seed',
    'Logger',
    'ConfigLoader',
    'create_directories',
    'worker_init_fn',
    'FlowerDataset',
    'load_class_mappings',
    'prepare_data_loaders',
    'get_train_transforms_fixed',
    'get_train_transforms_safe',
    'get_val_transforms',
    'get_test_transforms', 
    'get_tta_transforms',
    'MetricsCalculator',
    'save_model_checkpoint',
    'visualize_training_history_enhanced',
    'plot_confusion_matrix',
    'create_submission_file',
    'format_time',
    'print_model_summary'
]

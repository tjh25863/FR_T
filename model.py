"""
èŠ±å‰è¯†åˆ«AIæŒ‘æˆ˜èµ› - æ¨¡å‹å®šä¹‰æ–‡ä»¶ (ä¼˜åŒ–ç‰ˆ)
AI Competition Coach - Flower Recognition Challenge Model v1.1.0

ä¼˜åŒ–å†…å®¹:
1. ğŸŒ¡ï¸ æ·»åŠ æ¸©åº¦ç¼©æ”¾æå‡ç½®ä¿¡åº¦æ ¡å‡†
2. ğŸ“Š æ”¯æŒLabel Smoothingé™ä½Loss  
3. ğŸ¯ æ”¹è¿›æ¨¡å‹åˆå§‹åŒ–å’Œæƒé‡åŠ è½½
4. ğŸ”„ å¢å¼ºæ¨¡å‹ä¿å­˜å’ŒåŠ è½½åŠŸèƒ½
5. ğŸ“ˆ æ·»åŠ æ¨¡å‹æ€§èƒ½ç›‘æ§
6. ğŸ›¡ï¸ å¢å¼ºé”™è¯¯å¤„ç†å’Œæ—¥å¿—è®°å½•
"""

import torch
import torch.nn as nn
import torch.nn.functional as F
from transformers import (
    AutoModel, AutoConfig, ViTModel, ViTConfig, 
    ViTForImageClassification, AutoImageProcessor
)
from typing import Dict, Optional, Tuple, List
import warnings
import numpy as np
from pathlib import Path
import logging

warnings.filterwarnings('ignore')
warnings.filterwarnings("ignore", message=".*weights.*not initialized.*")
warnings.filterwarnings("ignore", message=".*mismatched sizes.*")

# è®¾ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)


class FlowerViTModel(nn.Module):
    """
    åŸºäºVision Transformerçš„èŠ±å‰è¯†åˆ«æ¨¡å‹ - ä¼˜åŒ–ç‰ˆ

    ä¸»è¦æ”¹è¿›:
    - æ¸©åº¦ç¼©æ”¾æ”¹å–„ç½®ä¿¡åº¦æ ¡å‡†  
    - æ›´å¥½çš„æƒé‡åˆå§‹åŒ–ç­–ç•¥
    - æ”¯æŒæ¸è¿›å¼è§£å†»è®­ç»ƒ
    - æ”¹è¿›çš„Dropoutç­–ç•¥
    """

    def __init__(self, 
                 model_name: str = "google/vit-base-patch16-224",
                 pretrained_path: str = "loretyan/vit-base-oxford-flowers-102", 
                 num_classes: int = 100,
                 dropout_rate: float = 0.1,
                 use_pretrained: bool = True,
                 freeze_backbone: bool = False,
                 temperature: float = 1.0,
                 label_smoothing: float = 0.0):
        """
        åˆå§‹åŒ–Vision Transformeræ¨¡å‹

        Args:
            model_name: åŸºç¡€æ¨¡å‹åç§°
            pretrained_path: é¢„è®­ç»ƒæ¨¡å‹è·¯å¾„
            num_classes: åˆ†ç±»ç±»åˆ«æ•°
            dropout_rate: Dropoutæ¦‚ç‡
            use_pretrained: æ˜¯å¦ä½¿ç”¨é¢„è®­ç»ƒæƒé‡
            freeze_backbone: æ˜¯å¦å†»ç»“backbone
            temperature: æ¸©åº¦ç¼©æ”¾å‚æ•°
            label_smoothing: æ ‡ç­¾å¹³æ»‘å‚æ•°
        """
        super(FlowerViTModel, self).__init__()

        self.num_classes = num_classes
        self.model_name = model_name  
        self.pretrained_path = pretrained_path
        self.temperature = temperature
        self.label_smoothing = label_smoothing

        logger.info(f"ğŸš€ åˆå§‹åŒ–ä¼˜åŒ–ç‰ˆVision Transformeræ¨¡å‹")
        logger.info(f"   åŸºç¡€æ¨¡å‹: {model_name}")
        logger.info(f"   é¢„è®­ç»ƒè·¯å¾„: {pretrained_path}")
        logger.info(f"   åˆ†ç±»æ•°é‡: {num_classes}")
        logger.info(f"   æ¸©åº¦å‚æ•°: {temperature}")
        logger.info(f"   æ ‡ç­¾å¹³æ»‘: {label_smoothing}")

        # åˆå§‹åŒ–æ¨¡å‹ç»„ä»¶
        self.vit = None
        self.config = None
        self._init_model(use_pretrained)

        # æ„å»ºæ”¹è¿›çš„åˆ†ç±»å¤´
        self._build_enhanced_classifier(dropout_rate)

        # åº”ç”¨å†»ç»“ç­–ç•¥
        if freeze_backbone:
            self.freeze_backbone(True)

        # æ”¹è¿›æƒé‡åˆå§‹åŒ–
        self._init_weights()

        logger.info(f"âœ… ä¼˜åŒ–ç‰ˆæ¨¡å‹åˆå§‹åŒ–å®Œæˆ")

    def _init_model(self, use_pretrained: bool):
        """åˆå§‹åŒ–ViTæ¨¡å‹"""
        try:
            if use_pretrained and self.pretrained_path:
                logger.info(f"ğŸ“¥ åŠ è½½é¢„è®­ç»ƒæ¨¡å‹: {self.pretrained_path}")

                # åŠ è½½å®Œæ•´çš„é¢„è®­ç»ƒæ¨¡å‹
                self.vit = ViTForImageClassification.from_pretrained(
                    self.pretrained_path,
                    num_labels=self.num_classes,
                    ignore_mismatched_sizes=True,
                    output_hidden_states=True,
                    output_attentions=False
                )

                self.config = self.vit.config
                logger.info(f"âœ… æˆåŠŸåŠ è½½é¢„è®­ç»ƒæ¨¡å‹")

            else:
                # åˆ›å»ºåŸºç¡€æ¨¡å‹
                logger.info(f"ğŸ“¦ åˆ›å»ºåŸºç¡€æ¨¡å‹: {self.model_name}")
                self.config = ViTConfig.from_pretrained(self.model_name)
                self.vit = ViTForImageClassification.from_pretrained(
                    self.model_name,
                    config=self.config,
                    num_labels=self.num_classes
                )
                logger.info(f"âœ… åŸºç¡€æ¨¡å‹åˆ›å»ºå®Œæˆ")

        except Exception as e:
            logger.error(f"âŒ æ¨¡å‹åˆå§‹åŒ–å¤±è´¥: {e}")
            # åˆ›å»ºé»˜è®¤æ¨¡å‹ä½œä¸ºåå¤‡
            self._create_default_model()

    def _create_default_model(self):
        """åˆ›å»ºé»˜è®¤æ¨¡å‹"""
        logger.warning("âš ï¸  åˆ›å»ºé»˜è®¤ViTæ¨¡å‹")
        self.config = ViTConfig(
            hidden_size=768,
            num_hidden_layers=12,
            num_attention_heads=12,
            image_size=224,
            patch_size=16,
            num_channels=3,
            num_labels=self.num_classes
        )
        self.vit = ViTForImageClassification(self.config)

    def _build_enhanced_classifier(self, dropout_rate: float):
        """æ„å»ºå¢å¼ºçš„åˆ†ç±»å¤´"""
        hidden_size = self.config.hidden_size

        # æ›¿æ¢åŸæœ‰åˆ†ç±»å¤´ä¸ºæ›´å¤æ‚çš„ç»“æ„
        self.enhanced_classifier = nn.Sequential(
            nn.Dropout(dropout_rate),
            nn.Linear(hidden_size, hidden_size // 2),
            nn.GELU(),
            nn.BatchNorm1d(hidden_size // 2),
            nn.Dropout(dropout_rate / 2),
            nn.Linear(hidden_size // 2, hidden_size // 4),
            nn.GELU(), 
            nn.BatchNorm1d(hidden_size // 4),
            nn.Dropout(dropout_rate / 4),
            nn.Linear(hidden_size // 4, self.num_classes)
        )

        # ä¿æŒåŸæœ‰ç®€å•åˆ†ç±»å¤´ç”¨äºå¯¹æ¯”
        self.simple_classifier = nn.Linear(hidden_size, self.num_classes)

        logger.info(f"ğŸ“Š å¢å¼ºåˆ†ç±»å¤´æ„å»ºå®Œæˆ")
        logger.info(f"   éšè—å±‚ç»´åº¦: {hidden_size} â†’ {hidden_size//2} â†’ {hidden_size//4} â†’ {self.num_classes}")

    def _init_weights(self):
        """æ”¹è¿›çš„æƒé‡åˆå§‹åŒ–"""
        def _init_layer(layer):
            if isinstance(layer, nn.Linear):
                # Xavieråˆå§‹åŒ–
                nn.init.xavier_uniform_(layer.weight)
                if layer.bias is not None:
                    nn.init.zeros_(layer.bias)
            elif isinstance(layer, nn.BatchNorm1d):
                nn.init.ones_(layer.weight)
                nn.init.zeros_(layer.bias)

        # åˆå§‹åŒ–å¢å¼ºåˆ†ç±»å¤´
        self.enhanced_classifier.apply(_init_layer)
        self.simple_classifier.apply(_init_layer)

        logger.info("ğŸ¯ æƒé‡åˆå§‹åŒ–å®Œæˆ")

    def forward(self, pixel_values: torch.Tensor, use_enhanced: bool = True):
        """
        å‰å‘ä¼ æ’­

        Args:
            pixel_values: è¾“å…¥å›¾åƒå¼ é‡
            use_enhanced: æ˜¯å¦ä½¿ç”¨å¢å¼ºåˆ†ç±»å¤´

        Returns:
            logits: åˆ†ç±»logits (åº”ç”¨æ¸©åº¦ç¼©æ”¾)
        """
        # è·å–ViTç‰¹å¾
        outputs = self.vit(pixel_values=pixel_values, output_hidden_states=True)

        # æå–CLS tokenç‰¹å¾
        if hasattr(outputs, 'hidden_states') and outputs.hidden_states is not None:
            # ä½¿ç”¨æœ€åä¸€å±‚çš„CLS token
            cls_features = outputs.hidden_states[-1][:, 0]  # [batch_size, hidden_size]
        else:
            # å¦‚æœæ²¡æœ‰hidden_statesï¼Œä½¿ç”¨pooler_output
            cls_features = outputs.pooler_output if hasattr(outputs, 'pooler_output') else outputs.logits

        # é€‰æ‹©åˆ†ç±»å¤´
        if use_enhanced:
            logits = self.enhanced_classifier(cls_features)
        else:
            logits = self.simple_classifier(cls_features)

        # åº”ç”¨æ¸©åº¦ç¼©æ”¾
        if self.temperature != 1.0:
            logits = logits / self.temperature

        return logits

    def get_features(self, pixel_values: torch.Tensor) -> torch.Tensor:
        """
        è·å–ç‰¹å¾å‘é‡

        Args:
            pixel_values: è¾“å…¥å›¾åƒå¼ é‡

        Returns:
            features: CLS tokenç‰¹å¾å‘é‡
        """
        with torch.no_grad():
            outputs = self.vit(pixel_values=pixel_values, output_hidden_states=True)
            features = outputs.hidden_states[-1][:, 0]  # CLS token
        return features


    def freeze_backbone(self, freeze: bool = True):
        """
        å†»ç»“/è§£å†»backboneå‚æ•°

        Args:
            freeze: æ˜¯å¦å†»ç»“
        """
        for param in self.vit.vit.parameters():
            param.requires_grad = not freeze

        # ç¡®ä¿åˆ†ç±»å¤´å‚æ•°å¯è®­ç»ƒ
        for param in self.enhanced_classifier.parameters():
            param.requires_grad = True
        for param in self.simple_classifier.parameters():
            param.requires_grad = True

        status = "å†»ç»“" if freeze else "è§£å†»"
        logger.info(f"ğŸ”’ Backboneå·²{status}")

    def unfreeze_last_layers(self, num_layers: int = 2):
        """
        è§£å†»æœ€åå‡ å±‚è¿›è¡Œç²¾ç»†è°ƒä¼˜

        Args:
            num_layers: è§£å†»çš„å±‚æ•°
        """
        # è§£å†»æœ€åå‡ ä¸ªtransformerå±‚
        total_layers = len(self.vit.vit.encoder.layer)
        start_layer = max(0, total_layers - num_layers)

        for i in range(start_layer, total_layers):
            for param in self.vit.vit.encoder.layer[i].parameters():
                param.requires_grad = True

        logger.info(f"ğŸ”“ è§£å†»æœ€å{num_layers}å±‚ (å±‚{start_layer}-{total_layers-1})")

    def get_model_info(self) -> Dict:
        """è·å–æ¨¡å‹ä¿¡æ¯"""
        total_params = sum(p.numel() for p in self.parameters())
        trainable_params = sum(p.numel() for p in self.parameters() if p.requires_grad)

        return {
            'total_params': total_params,
            'trainable_params': trainable_params, 
            'model_size_mb': total_params * 4 / 1024 / 1024,
            'trainable_ratio': trainable_params / total_params,
            'temperature': self.temperature,
            'num_classes': self.num_classes
        }

    def set_temperature(self, temperature: float):
        """è®¾ç½®æ¸©åº¦å‚æ•°"""
        self.temperature = temperature
        logger.info(f"ğŸŒ¡ï¸  æ¸©åº¦å‚æ•°æ›´æ–°ä¸º: {temperature}")

    def get_attention_weights(self, pixel_values: torch.Tensor) -> torch.Tensor:
        """
        è·å–æ³¨æ„åŠ›æƒé‡ç”¨äºå¯è§†åŒ–

        Args:
            pixel_values: è¾“å…¥å›¾åƒå¼ é‡

        Returns:
            attention_weights: æ³¨æ„åŠ›æƒé‡
        """
        with torch.no_grad():
            outputs = self.vit(pixel_values=pixel_values, output_attentions=True)
            # è¿”å›æœ€åä¸€å±‚çš„æ³¨æ„åŠ›æƒé‡
            return outputs.attentions[-1] if outputs.attentions else None


class ModelFactory:
    """æ¨¡å‹å·¥å‚ç±» - ä¼˜åŒ–ç‰ˆ"""

    @staticmethod
    def create_vit_model(config: Dict) -> FlowerViTModel:
        """
        åˆ›å»ºViTæ¨¡å‹

        Args:
            config: é…ç½®å­—å…¸

        Returns:
            FlowerViTModelå®ä¾‹
        """
        model_config = config['model']
        training_config = config.get('training', {})

        model = FlowerViTModel(
            model_name=model_config.get('name', 'google/vit-base-patch16-224'),
            pretrained_path=model_config.get('pretrained_model', 'loretyan/vit-base-oxford-flowers-102'),
            num_classes=model_config.get('num_classes', 100),
            dropout_rate=model_config.get('dropout', 0.1),
            use_pretrained=True,
            freeze_backbone=model_config.get('freeze_backbone', False),
            temperature=model_config.get('temperature', 1.0),
            label_smoothing=training_config.get('label_smoothing', 0.0)
        )

        return model

    @staticmethod
    def create_ensemble_models(config: Dict, num_models: int = 3, 
                             different_seeds: bool = True) -> List[FlowerViTModel]:
        """
        åˆ›å»ºé›†æˆæ¨¡å‹

        Args:
            config: é…ç½®å­—å…¸
            num_models: æ¨¡å‹æ•°é‡
            different_seeds: æ˜¯å¦ä½¿ç”¨ä¸åŒéšæœºç§å­

        Returns:
            æ¨¡å‹åˆ—è¡¨
        """
        models = []
        base_seed = config.get('reproducibility', {}).get('seed', 42)

        for i in range(num_models):
            if different_seeds:
                # è®¾ç½®ä¸åŒçš„éšæœºç§å­
                torch.manual_seed(base_seed + i)

            model = ModelFactory.create_vit_model(config)
            models.append(model)

            logger.info(f"ğŸ² é›†æˆæ¨¡å‹ {i+1}/{num_models} åˆ›å»ºå®Œæˆ")

        return models


class ModelUtils:
    """æ¨¡å‹å·¥å…·ç±» - ä¼˜åŒ–ç‰ˆ"""

    @staticmethod
    def print_model_info(model: nn.Module):
        """æ‰“å°æ¨¡å‹ä¿¡æ¯"""
        if hasattr(model, 'get_model_info'):
            info = model.get_model_info()
            logger.info("ğŸ“Š æ¨¡å‹ä¿¡æ¯:")
            logger.info(f"   æ€»å‚æ•°é‡: {info['total_params']:,}")
            logger.info(f"   å¯è®­ç»ƒå‚æ•°: {info['trainable_params']:,}")
            logger.info(f"   æ¨¡å‹å¤§å°: {info['model_size_mb']:.2f} MB")
            logger.info(f"   å¯è®­ç»ƒæ¯”ä¾‹: {info['trainable_ratio']:.2%}")
            logger.info(f"   æ¸©åº¦å‚æ•°: {info['temperature']}")
            logger.info(f"   åˆ†ç±»ç±»åˆ«: {info['num_classes']}")

    @staticmethod
    def save_model_weights(model: nn.Module, save_path: str, 
                          additional_info: Optional[Dict] = None,
                          save_config: bool = True):
        """
        ä¿å­˜æ¨¡å‹æƒé‡ - å¢å¼ºç‰ˆ

        Args:
            model: æ¨¡å‹å®ä¾‹
            save_path: ä¿å­˜è·¯å¾„
            additional_info: é¢å¤–ä¿¡æ¯
            save_config: æ˜¯å¦ä¿å­˜é…ç½®
        """
        save_dict = {
            'model_state_dict': model.state_dict(),
            'model_info': model.get_model_info() if hasattr(model, 'get_model_info') else {},
            'save_time': torch.tensor([torch.now()]) if hasattr(torch, 'now') else None
        }

        if additional_info:
            save_dict.update(additional_info)

        if save_config and hasattr(model, 'config'):
            save_dict['model_config'] = model.config

        Path(save_path).parent.mkdir(parents=True, exist_ok=True)
        torch.save(save_dict, save_path)
        logger.info(f"âœ… æ¨¡å‹æƒé‡å·²ä¿å­˜: {save_path}")

    @staticmethod
    def load_model_weights(model: nn.Module, checkpoint_path: str,
                          strict: bool = False) -> Dict:
        """
        åŠ è½½æ¨¡å‹æƒé‡ - å¢å¼ºç‰ˆ

        Args:
            model: æ¨¡å‹å®ä¾‹
            checkpoint_path: æ£€æŸ¥ç‚¹è·¯å¾„
            strict: æ˜¯å¦ä¸¥æ ¼åŒ¹é…æƒé‡

        Returns:
            åŠ è½½ä¿¡æ¯å­—å…¸
        """
        try:
            checkpoint = torch.load(checkpoint_path, map_location='cpu')

            if 'model_state_dict' in checkpoint:
                state_dict = checkpoint['model_state_dict']
            else:
                state_dict = checkpoint

            # åŠ è½½æƒé‡
            missing_keys, unexpected_keys = model.load_state_dict(state_dict, strict=strict)

            load_info = {
                'missing_keys': missing_keys,
                'unexpected_keys': unexpected_keys,
                'checkpoint_info': {k: v for k, v in checkpoint.items() if k != 'model_state_dict'}
            }

            logger.info(f"âœ… æ¨¡å‹æƒé‡åŠ è½½å®Œæˆ: {checkpoint_path}")
            if missing_keys:
                logger.warning(f"âš ï¸  ç¼ºå¤±æƒé‡: {len(missing_keys)} ä¸ª")
            if unexpected_keys:
                logger.warning(f"âš ï¸  å¤šä½™æƒé‡: {len(unexpected_keys)} ä¸ª")

            return load_info

        except Exception as e:
            logger.error(f"âŒ æƒé‡åŠ è½½å¤±è´¥: {e}")
            return {'error': str(e)}

    @staticmethod
    def count_parameters(model: nn.Module) -> Tuple[int, int]:
        """
        ç»Ÿè®¡å‚æ•°æ•°é‡

        Returns:
            total_params, trainable_params
        """
        total = sum(p.numel() for p in model.parameters())
        trainable = sum(p.numel() for p in model.parameters() if p.requires_grad)
        return total, trainable

    @staticmethod
    def get_learning_rates(optimizer: torch.optim.Optimizer) -> List[float]:
        """è·å–å½“å‰å­¦ä¹ ç‡"""
        return [group['lr'] for group in optimizer.param_groups]


class EnsembleModel(nn.Module):
    """é›†æˆæ¨¡å‹ç±»"""

    def __init__(self, models: List[nn.Module], weights: Optional[List[float]] = None):
        """
        åˆå§‹åŒ–é›†æˆæ¨¡å‹

        Args:
            models: æ¨¡å‹åˆ—è¡¨
            weights: é›†æˆæƒé‡
        """
        super(EnsembleModel, self).__init__()
        self.models = nn.ModuleList(models)
        self.weights = weights or [1.0] * len(models)
        self.weights = torch.tensor(self.weights)

        logger.info(f"ğŸ¯ é›†æˆæ¨¡å‹åˆå§‹åŒ–å®Œæˆï¼ŒåŒ…å« {len(models)} ä¸ªå­æ¨¡å‹")

    def forward(self, x: torch.Tensor) -> torch.Tensor:
        """å‰å‘ä¼ æ’­é›†æˆé¢„æµ‹"""
        outputs = []

        for model in self.models:
            with torch.no_grad():
                output = model(x)
                outputs.append(F.softmax(output, dim=1))

        # åŠ æƒå¹³å‡
        ensemble_output = torch.zeros_like(outputs[0])
        total_weight = 0

        for i, output in enumerate(outputs):
            weight = self.weights[i]
            ensemble_output += weight * output
            total_weight += weight

        ensemble_output /= total_weight
        return torch.log(ensemble_output)  # è¿”å›logæ¦‚ç‡ç”¨äºæŸå¤±è®¡ç®—

    def predict(self, x: torch.Tensor) -> torch.Tensor:
        """é¢„æµ‹æ–¹æ³•"""
        self.eval()
        with torch.no_grad():
            logits = self.forward(x)
            return F.softmax(logits, dim=1)


# å¯¼å‡ºä¸»è¦ç±»å’Œå‡½æ•°
__all__ = [
    'FlowerViTModel',
    'ModelFactory', 
    'ModelUtils',
    'EnsembleModel'
]
